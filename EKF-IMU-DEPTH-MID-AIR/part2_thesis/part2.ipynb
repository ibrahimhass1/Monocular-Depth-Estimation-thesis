{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a flag to check if %cd .. has been run\n",
    "if 'cd_executed' not in globals():\n",
    "    %cd ..\n",
    "    cd_executed = True  # Set the flag to True after the command runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liegroups.numpy import SO3 as SO3_np\n",
    "import tqdm\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pdb\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import json\n",
    "\n",
    "from utils import *\n",
    "from kitti_utils import *\n",
    "from layers import *\n",
    "\n",
    "import datasets\n",
    "# import networks\n",
    "from networks.velo_decoder import VeloDecoder\n",
    "from networks.gravity_decoder import GravityDecoder\n",
    "from networks.depth_decoder import DepthDecoder\n",
    "from networks.resnet_encoder import ResnetEncoder\n",
    "from ekf import EKFModel\n",
    "from ekf import proc_vis_covar\n",
    "\n",
    "from options import MonodepthOptions\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "# Metrics\n",
    "import importlib\n",
    "import cv2\n",
    "import datasets.midair\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackprojectDepth(nn.Module):\n",
    "    \"\"\"Layer to transform a depth image into a point cloud\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size, height, width):\n",
    "        super(BackprojectDepth, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        meshgrid = np.meshgrid(range(self.width), range(self.height), indexing='xy')\n",
    "        self.id_coords = np.stack(meshgrid, axis=0).astype(np.float32)\n",
    "        self.id_coords = nn.Parameter(torch.from_numpy(self.id_coords),\n",
    "                                      requires_grad=False)\n",
    "\n",
    "        self.ones = nn.Parameter(torch.ones(self.batch_size, 1, self.height * self.width),\n",
    "                                 requires_grad=False)\n",
    "\n",
    "        self.pix_coords = torch.unsqueeze(torch.stack(\n",
    "            [self.id_coords[0].view(-1), self.id_coords[1].view(-1)], 0), 0)\n",
    "        self.pix_coords = self.pix_coords.repeat(batch_size, 1, 1)\n",
    "        self.pix_coords = nn.Parameter(torch.cat([self.pix_coords, self.ones], 1),\n",
    "                                       requires_grad=False)\n",
    "\n",
    "    def forward(self, depth, inv_K):\n",
    "        cam_points = torch.matmul(inv_K[:, :3, :3], self.pix_coords)\n",
    "\n",
    "        cam_points = depth.view(self.batch_size, 1, -1) * cam_points\n",
    "        cam_points = torch.cat([cam_points, self.ones], 1)\n",
    "\n",
    "        return cam_points\n",
    "\n",
    "\n",
    "class Project3D(nn.Module):\n",
    "    \"\"\"Layer which projects 3D points into a camera with intrinsics K and at position T\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size, height, width, eps=1e-7):\n",
    "        super(Project3D, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, points, K, T):\n",
    "        P = torch.matmul(K, T)[:, :3, :]\n",
    "\n",
    "        cam_points = torch.matmul(P, points)\n",
    "\n",
    "        pix_coords = cam_points[:, :2, :] / (cam_points[:, 2, :].unsqueeze(1) + self.eps)\n",
    "        pix_coords = pix_coords.view(self.batch_size, 2, self.height, self.width)\n",
    "        pix_coords = pix_coords.permute(0, 2, 3, 1)\n",
    "        pix_coords[..., 0] /= self.width - 1\n",
    "        pix_coords[..., 1] /= self.height - 1\n",
    "        pix_coords = (pix_coords - 0.5) * 2\n",
    "        return pix_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_imu_pose_with_inv(alpha, R_c, R_cbt_bc, delta_t, gravities, velocities, trans_scale_factor):\n",
    "    \"\"\"\n",
    "    -> Rotation is directly obtained using preintegrated q\n",
    "    -> Translation is obtained by preintegrated alpha and q\n",
    "    -> Return:\n",
    "        -> poses: [from 0 to -1, from 0 to 1]\n",
    "        -> poses_inv: [from -1 to 0, from 1 to 0]\n",
    "    \"\"\"\n",
    "    # NOTE: T_c denotes [from 0 to -1, from 1 to 0]\n",
    "    # NOTE: T_c_inv denotes [from -1 to 0, from 0 to 1]\n",
    "    T_c, T_c_inv = [], []\n",
    "    for i in [0]:\n",
    "        rot = R_c[i] # [B, 3, 3]\n",
    "        dt = delta_t[i].unsqueeze(-1).unsqueeze(-1) # [B, 1, 1]\n",
    "        trans = alpha[i].unsqueeze(-1) + R_c[i] @ R_cbt_bc[i].unsqueeze(-1) - R_cbt_bc[i].unsqueeze(-1) - 0.5 * gravities[i].unsqueeze(-1) * dt * dt + velocities[i].unsqueeze(-1) * dt # [B, 3, 1]\n",
    "        \n",
    "        # NOTE: trans is re-scaled by 5.4, but gravities and velocities are still the original scale\n",
    "        trans = trans / trans_scale_factor\n",
    "                \n",
    "        T_mat = torch.cat([rot, trans], dim=2) # [B, 3, 4]\n",
    "        fill = T_mat.new_zeros([T_mat.shape[0], 1, 4]) # [B, 1, 4]\n",
    "        fill[:, :, -1] = 1\n",
    "        T_mat = torch.cat([T_mat, fill], dim=1) # [B, 4, 4]\n",
    "        T_c.append(T_mat) # [B, 4, 4]\n",
    "        T_c_inv.append(T_mat.inverse()) # [B, 4, 4]\n",
    "    \n",
    "    # NOTE: the indices in poses/poses_inv are different from T_c/T_c_inv\n",
    "    # -> poses: [from 0 to -1, from 0 to 1]\n",
    "    # -> poses_inv: [from -1 to 0, from 1 to 0]\n",
    "    # poses = [T_c_inv[0],T_mat[0]]\n",
    "    poses = [T_c[0], T_c_inv[0]]\n",
    "    return poses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    # remove empty items\n",
    "    batch = [item for item in batch if item !={}]\n",
    "    return torch.utils.data.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_sort_key(item):\n",
    "    # Extract components from the filepath\n",
    "    parts = item.split('/')\n",
    "    kite_training = parts[0]  # 'Kite_training'\n",
    "    weather = parts[1]        # e.g., 'cloudy'\n",
    "    sensor = parts[2]         # e.g., 'sensor'\n",
    "    trajectory_part = parts[3]  # e.g., 'trajectory_3000 397 l'\n",
    "\n",
    "    # Split the trajectory part\n",
    "    trajectory_str, number_str, *rest = trajectory_part.split(' ')\n",
    "\n",
    "    # Extract the trajectory number and convert to integer\n",
    "    trajectory_num = int(trajectory_str.replace('trajectory_', ''))\n",
    "\n",
    "    # Check if number_str contains a range (e.g., '397-400')\n",
    "    if '-' in number_str:\n",
    "        # Extract the range numbers\n",
    "        range_numbers = list(map(int, number_str.split('-')))\n",
    "        number = range_numbers[0]  # Use the start of the range for sorting\n",
    "    else:\n",
    "        number = int(number_str)\n",
    "\n",
    "    # Return a tuple as the sort key in the desired order\n",
    "    return (kite_training, weather, sensor, trajectory_num, number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(\"splits\", \"eigen_midair\", \"{}_files.txt\"))\n",
    "fpath = os.path.join(\"splits\",\"eigen_midair\", \"{}_files.txt\")\n",
    "\n",
    "train_filenames = readlines(fpath.format(\"test\"))\n",
    "\n",
    "train_filenames = sorted(train_filenames, key=custom_sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.midair.MidAirDataset\n",
    "\n",
    "fpath = os.path.join(\"splits\",\"eigen_midair\", \"{}_files.txt\")\n",
    "train_filenames = readlines(fpath.format(\"test\"))\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models[\"velo_encoder\"] = ResnetEncoder(\n",
    "    18,\n",
    "    \"pretrained\",\n",
    "    num_input_images=2)\n",
    "\n",
    "models[\"velo\"] = VeloDecoder(\n",
    "    models[\"velo_encoder\"].num_ch_enc,\n",
    "    num_input_features=1,\n",
    "    num_frames_to_predict_for=1)\n",
    "\n",
    "\n",
    "# Initialize gravity networks\n",
    "models[\"gravity_encoder\"] = ResnetEncoder(\n",
    "    18,\n",
    "    \"pretrained\",\n",
    "    num_input_images=2)\n",
    "\n",
    "\n",
    "models[\"gravity\"] = GravityDecoder(\n",
    "    models[\"gravity_encoder\"].num_ch_enc,\n",
    "    num_input_features=1,\n",
    "    num_frames_to_predict_for=1)\n",
    "\n",
    "\n",
    "models[\"encoder\"] = ResnetEncoder(\n",
    "            50,\n",
    "            False)\n",
    "\n",
    "\n",
    "models[\"depth\"] = DepthDecoder(\n",
    "    models[\"encoder\"].num_ch_enc,scales=range(1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights_folder = \"/Users/ibrahimhassan/Documents/Documents/thesis_DynaDepth/tmp_training_use_imu_True_use_ekf_True/dynadepth_20241014/models/weights_29\"\n",
    "vel_encoder_path = os.path.join(load_weights_folder, \"velo_encoder.pth\")\n",
    "vel_path = os.path.join(load_weights_folder, \"velo.pth\")\n",
    "\n",
    "grav_encoder_path = os.path.join(load_weights_folder, \"gravity_encoder.pth\")\n",
    "grav_path = os.path.join(load_weights_folder, \"gravity.pth\")\n",
    "\n",
    "encoder_path = os.path.join(load_weights_folder, \"encoder.pth\")\n",
    "decoder_path = os.path.join(load_weights_folder, \"depth.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"velo_encoder\"].load_state_dict(torch.load(vel_encoder_path,map_location=torch.device('cpu')))\n",
    "models[\"velo\"].load_state_dict(torch.load(vel_path,map_location=torch.device('cpu')))\n",
    "models[\"gravity_encoder\"].load_state_dict(torch.load(grav_encoder_path,map_location=torch.device('cpu')))\n",
    "models[\"gravity\"].load_state_dict(torch.load(grav_path,map_location=torch.device('cpu')))\n",
    "\n",
    "encoder_dict = torch.load(encoder_path,map_location=torch.device('cpu'))\n",
    "models[\"encoder\"].load_state_dict({k: v for k, v in encoder_dict.items() if k in models[\"encoder\"].state_dict()})\n",
    "models[\"depth\"].load_state_dict(torch.load(decoder_path,map_location=torch.device('cpu')))\n",
    "models[\"encoder\"].eval();\n",
    "models[\"depth\"].eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_pose(pose):\n",
    "    \n",
    "    pose_red = torch.squeeze(pose)\n",
    "    # R = torch.squeeze(pose[:3, :3])\n",
    "    # t = torch.squeeze(pose[:3, 3:])\n",
    "    \n",
    "    R = pose_red[:3, :3]\n",
    "    t = pose_red[:3, 3:]\n",
    "    R_inv = R.transpose(0, 1)\n",
    "    t_inv = -torch.matmul(R_inv, t)\n",
    "    pose_inv = torch.eye(4).to(pose.device)\n",
    "    pose_inv[:3, :3] = R_inv\n",
    "    pose_inv[:3, 3:] = t_inv\n",
    "    return pose_inv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poses_depth(data_load, models, alpha, R_c, R_cbt_bc, delta_t, TRANS_SCALE_FACTOR):\n",
    "    IMU_sequence = []\n",
    "    Images_sequence = []\n",
    "    list_poses = []\n",
    "    for idx, data in enumerate(data_load):\n",
    "\n",
    "\n",
    "        for key, ipt in data.items():\n",
    "            if key in [(\"preint_imu\", -1, 0), (\"preint_imu\", 0, 1)]:\n",
    "                for pkey, pipt in data[key].items():\n",
    "                    data[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                    if pkey not in [\"v_norm\", \"delta_t\"]:\n",
    "                        pipt = pipt.unsqueeze(0)\n",
    "                        data[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                    else:\n",
    "                        data[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "            else:\n",
    "                ipt = ipt.unsqueeze(0)\n",
    "                data[key] = ipt.to(device, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "        IMU = data[('preint_imu', 0, 1)]\n",
    "        IMU_sequence.append(IMU)\n",
    "        Images_sequence.append(data[('color', 0, 0)])\n",
    "\n",
    "        # Get IMU POSES\n",
    "        pair_inputs = [data[('color', 0, 0)], data[('color', 1, 0)]]\n",
    "\n",
    "        velo_inputs = [models[\"velo_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "        gravity_inputs = [models[\"gravity_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "\n",
    "        velocity = models[\"velo\"](velo_inputs)\n",
    "        gravity = models[\"gravity\"](gravity_inputs)\n",
    "\n",
    "        poses = compute_imu_pose_with_inv(alpha, R_c, R_cbt_bc, delta_t, gravity, velocity, TRANS_SCALE_FACTOR)\n",
    "        list_poses.append(poses[0])\n",
    "\n",
    "    return list_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth_trajectory(batch_size, init_image, depth_init, list_poses, data):\n",
    "\n",
    "    depth_after_imu = [depth_init]\n",
    "    list_images_imu = [init_image]\n",
    "    depth_loop = depth_init\n",
    "\n",
    "    for i in range(len(list_poses) - 1):\n",
    "        inv_pose = invert_pose(list_poses[i])\n",
    "\n",
    "        DEPTH_POINT_CLOUDS = backproject_depth(depth_loop, data[(\"inv_K\", 0)])\n",
    "        P = torch.matmul(data[(\"K\", 0)], inv_pose)[:, :3, :]\n",
    "        TRANSFORMED_DEPTH_POINT_CLOUDS_FOR_Z = torch.matmul(P, DEPTH_POINT_CLOUDS)\n",
    "\n",
    "        # Update depth\n",
    "        new_depth = TRANSFORMED_DEPTH_POINT_CLOUDS_FOR_Z[:, 2, :].view(batch_size, 1, height, width)\n",
    "\n",
    "        P = torch.matmul(data[(\"K\", 0)], list_poses[i])[:, :3, :]\n",
    "        TRANSFORMED_DEPTH_POINT_CLOUDS = torch.matmul(P, DEPTH_POINT_CLOUDS)\n",
    "\n",
    "        pix_coords_depth = TRANSFORMED_DEPTH_POINT_CLOUDS[:, :2, :] / (TRANSFORMED_DEPTH_POINT_CLOUDS[:, 2, :].unsqueeze(1) + 0.001)\n",
    "        pix_coords_depth = pix_coords_depth.view(batch_size, 2, height, width)\n",
    "        pix_coords_depth = pix_coords_depth.permute(0, 2, 3, 1)\n",
    "        pix_coords_depth[..., 0] /= width - 1\n",
    "        pix_coords_depth[..., 1] /= height - 1\n",
    "        pix_coords_depth = (pix_coords_depth - 0.5) * 2\n",
    "\n",
    "        depth_loop = F.grid_sample(new_depth, pix_coords_depth, padding_mode=\"border\")\n",
    "        depth_after_imu.append(depth_loop)\n",
    "\n",
    "        # Warp the initial image to new pose\n",
    "        pix_coords_image = project_3d(DEPTH_POINT_CLOUDS, data[(\"K\", 0)], list_poses[i])\n",
    "        new_transformed_image = F.grid_sample(list_images_imu[i], pix_coords_image, padding_mode=\"border\")\n",
    "        list_images_imu.append(new_transformed_image)\n",
    "\n",
    "    return depth_after_imu, depth_init, list_images_imu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_depth(depth_after_imu, filename):\n",
    "\n",
    "    # Example data (you can replace this with your actual frames)\n",
    "    frames = depth_after_imu  # List of 50 random frames\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Create an initial frame\n",
    "    frame_data = frames[0]\n",
    "    # print(frame_data[0].permute(1,2,0).detach().numpy())\n",
    "    # im = ax.imshow(frame_data[0].permute(1,2,0).detach().numpy(), cmap='viridis')\n",
    "    im = ax.imshow(frame_data[0].permute(1,2,0).detach().numpy(), cmap='viridis')\n",
    "\n",
    "    # Update function for animation\n",
    "    def update(frame):\n",
    "        # print(frame[0].permute(1,2,0).detach().numpy().shape)\n",
    "        # im.set_data(frame[0].permute(1,2,0).detach().numpy()\n",
    "        im.set_data(frame[0].permute(1,2,0).detach().numpy())\n",
    "        return [im]\n",
    "\n",
    "    # Create an animation\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig, update, frames=frames, interval=100, blit=True\n",
    "    )\n",
    "\n",
    "    # Save the animation as a video file (e.g., MP4)\n",
    "    ani.save(filename, writer='ffmpeg', fps=30)\n",
    "\n",
    "    # To display the animation in a notebook (optional)\n",
    "    # from IPython.display import HTML\n",
    "    # HTML(ani.to_jshtml())\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code\n",
    "# INIT DEPTH PREDICTION\n",
    "min_depth = 0.1\n",
    "max_depth = 80\n",
    "\n",
    "height = 512\n",
    "width = 512\n",
    "batch_size = 1\n",
    "\n",
    "backproject_depth = BackprojectDepth(batch_size, height, width)\n",
    "project_3d = Project3D(batch_size, height, width)\n",
    "fraction_trajectory_1 = train_filenames[1633:1633+100]\n",
    "\n",
    "dataset = datasets.midair.MidAirDataset\n",
    "fpath = os.path.join(\"splits\", \"eigen_midair\", \"{}_files.txt\")\n",
    "data_path = \"MidAir\"\n",
    "\n",
    "print(\"Creating dataset trajectory 1\")\n",
    "dataset_trajectory_1 = dataset(\n",
    "    data_path, fraction_trajectory_1, \n",
    "    height, width,\n",
    "    [0, -1, 1],\n",
    "    select_file_names=True,\n",
    "    num_scales=1, \n",
    "    use_imu=True,\n",
    "    k_imu_clip=5, is_train=False, img_ext='.jpg' \n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_errors(gt, pred):\n",
    "    \"\"\"Compute error metrics between predicted and ground truth depths.\"\"\"\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25     ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse = np.sqrt(((gt - pred) ** 2).mean())\n",
    "    rmse_log = np.sqrt(((np.log(gt) - np.log(pred)) ** 2).mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "    sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
    "\n",
    "    return abs_rel, sq_rel, rmse, rmse_log, a1, a2, a3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "dataloader_trajectory_1 = DataLoader(dataset_trajectory_1, 1, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "list_frames_traj_1 = []\n",
    "list_gt_frames_traj_1 = []\n",
    "depth_gt_list = []  # List to store ground truth depth maps\n",
    "alpha, R_c, R_cbt_bc, delta_t, gravities, velocities = [], [], [], [], [], []\n",
    "\n",
    "avg_velocity = []\n",
    "\n",
    "for idx, sample in enumerate(dataset_trajectory_1):\n",
    "    # Standard processing\n",
    "    for key, ipt in sample.items():\n",
    "        if key in [(\"preint_imu\", -1, 0), (\"preint_imu\", 0, 1)]:\n",
    "            for pkey, pipt in sample[key].items():\n",
    "                sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                if pkey not in [\"v_norm\", \"delta_t\"]:\n",
    "                    pipt = pipt.unsqueeze(0)\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                else:\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "        else:\n",
    "            ipt = ipt.unsqueeze(0)\n",
    "            sample[key] = ipt.to(device, dtype=torch.float32)\n",
    "\n",
    "    if idx == 0:\n",
    "        init_sample = sample\n",
    "        init_image = sample[('color', 0, 0)]\n",
    "        disp_gt_batch = sample[\"disp_gt\"]\n",
    "        depth_gt_init = (height // 2) / disp_gt_batch.to(torch.float32)\n",
    "        depth_gt_init = torch.clamp(depth_gt_init, min_depth, max_depth)\n",
    "        depth_gt_init = depth_gt_init[:, 0].detach()\n",
    "\n",
    "    frames = sample[('color', 0, 0)]\n",
    "    disp_gt = sample[\"disp_gt\"]\n",
    "    disp_gt = (height // 2) / disp_gt.to(torch.float32)\n",
    "    disp_gt = torch.clamp(disp_gt, min_depth, max_depth)\n",
    "    depth_gt_sample = disp_gt[:, 0].detach()\n",
    "\n",
    "    # Store ground truth depth maps\n",
    "    depth_gt_list.append(depth_gt_sample.cpu())\n",
    "\n",
    "    # Collect frames for visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(10, 10), nrows=1, ncols=2)\n",
    "    frame_data = frames\n",
    "    im_1 = ax1.imshow(frame_data[0].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    im_2 = ax2.imshow(depth_gt_sample.permute(1, 2, 0).cpu().numpy(), cmap='viridis_r')\n",
    "    list_frames_traj_1.append(im_1)\n",
    "    list_gt_frames_traj_1.append(im_2)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Get IMU parameters\n",
    "    next_imu = sample[('preint_imu', -1, 0)]\n",
    "    alpha.append(next_imu[\"alpha\"])\n",
    "    R_c.append(next_imu[\"R_c\"])\n",
    "    R_cbt_bc.append(next_imu[\"R_cbt_bc\"])\n",
    "    delta_t.append(next_imu[\"delta_t\"])\n",
    "    avg_velocity.append(next_imu[\"v_norm\"])\n",
    "\n",
    "# Compute average velocity\n",
    "vel_1 = torch.mean(torch.stack(avg_velocity), dim=0)\n",
    "print(f\"Average velocity: {vel_1}\")\n",
    "\n",
    "# Add code to create video of the original trajectory\n",
    "image_frames_traj_1 = [im.get_array() for im in list_frames_traj_1]\n",
    "gt_frames_traj_1 = [im.get_array() for im in list_gt_frames_traj_1]\n",
    "\n",
    "# Create a figure and axis for the animation\n",
    "fig, ax = plt.subplots()\n",
    "# Initialize the image on the axis (using the first frame's shape)\n",
    "im = ax.imshow(image_frames_traj_1[0], cmap='viridis')\n",
    "\n",
    "# Update function for animation\n",
    "def update(frame):\n",
    "    im.set_data(frame)\n",
    "    return [im]\n",
    "\n",
    "# Create an animation\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, update, frames=image_frames_traj_1, interval=100, blit=True\n",
    ")\n",
    "\n",
    "# Save the animation as a video file (e.g., MP4)\n",
    "ani.save('Trajectories_anim/trajectory_1.mp4', writer='ffmpeg', fps=25)\n",
    "plt.close(fig)\n",
    "\n",
    "# Depth prediction using the same method as the second file\n",
    "TRANS_SCALE_FACTOR = 5.4\n",
    "pair_inputs = [init_sample[('color', 0, 0)], init_sample[('color', 1, 0)]]\n",
    "\n",
    "# Generate velocity and gravity inputs\n",
    "velo_inputs = [models[\"velo_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "gravity_inputs = [models[\"gravity_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "\n",
    "velocity = models[\"velo\"](velo_inputs)\n",
    "gravity = models[\"gravity\"](gravity_inputs)\n",
    "\n",
    "R_cbt_bc[0] = R_cbt_bc[0]\n",
    "\n",
    "# Get depth prediction\n",
    "with torch.no_grad():\n",
    "    output = models[\"depth\"](models[\"encoder\"](init_image))\n",
    "    disp_trajectory_1 = output\n",
    "\n",
    "# Adjusted depth prediction\n",
    "pred_disp, _ = disp_to_depth(disp_trajectory_1[(\"disp\", 0)], min_depth, max_depth)\n",
    "pred_disp = pred_disp.cpu()[:, 0]\n",
    "pred_depth = 1 / pred_disp\n",
    "\n",
    "# Apply median scaling\n",
    "ratio = np.median(depth_gt_init.cpu().numpy()) / np.median(pred_depth.cpu().numpy())\n",
    "pred_depth *= ratio\n",
    "pred_depth = pred_depth.to(init_image.device).unsqueeze(0)\n",
    "\n",
    "# Compute errors between predicted and ground truth depths\n",
    "##########################################################\n",
    "pred_depth_tmp = pred_depth.squeeze()\n",
    "pred_depth_tmp = pred_depth_tmp.detach().cpu().numpy()\n",
    "depth_gt_init_tmp = depth_gt_init.squeeze()\n",
    "depth_gt_init_tmp = depth_gt_init_tmp.detach().cpu().numpy()\n",
    "\n",
    "mask = (depth_gt_init_tmp > min_depth) & (depth_gt_init_tmp < max_depth)\n",
    "pred_depth_flat = pred_depth_tmp[mask]\n",
    "\n",
    "gt_depth_flat = depth_gt_init_tmp[mask]\n",
    "print(f\"init error : {compute_errors(gt_depth_flat, pred_depth_flat)[2]}\")\n",
    "##########################################################\n",
    "\n",
    "# Generate poses and depth trajectory\n",
    "poses_depth = get_poses_depth(dataset_trajectory_1, models, alpha, R_c, R_cbt_bc, delta_t, TRANS_SCALE_FACTOR)\n",
    "depth_after_imu, depth_init_trajectory_1, images_after_imu = get_depth_trajectory(\n",
    "    batch_size, init_image, pred_depth, poses_depth, init_sample\n",
    ")\n",
    "\n",
    "# Save depth video\n",
    "get_video_depth(depth_after_imu, \"Depth_anim/depth_trajectory_1.mp4\")\n",
    "\n",
    "# Function to compute errors\n",
    "def compute_errors(gt, pred):\n",
    "    \"\"\"Compute error metrics between predicted and ground truth depths.\"\"\"\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25     ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse = np.sqrt(((gt - pred) ** 2).mean())\n",
    "    rmse_log = np.sqrt(((np.log(gt) - np.log(pred)) ** 2).mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "    sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
    "\n",
    "    return abs_rel, sq_rel, rmse, rmse_log, a1, a2, a3\n",
    "\n",
    "# Now, compute errors between the predicted depth maps and ground truth\n",
    "# Collect predicted depth maps from depth_after_imu\n",
    "predicted_depth_maps = [depth.cpu().squeeze(0) for depth in depth_after_imu]\n",
    "\n",
    "errors_trajectory_1 = []\n",
    "\n",
    "for pred_depth_map, gt_depth_map in zip(predicted_depth_maps, depth_gt_list):\n",
    "    pred_depth_map_np = pred_depth_map.detach().numpy() \n",
    "    gt_depth_map_np = gt_depth_map.numpy()\n",
    "    \n",
    "    # Apply mask to valid depth values\n",
    "    mask = (gt_depth_map_np > min_depth) & (gt_depth_map_np < max_depth)\n",
    "    \n",
    "    pred_depth_flat = pred_depth_map_np[mask]\n",
    "    gt_depth_flat = gt_depth_map_np[mask]\n",
    "    \n",
    "    # Ensure predicted depths are within valid range\n",
    "    pred_depth_flat = np.clip(pred_depth_flat, min_depth, max_depth)\n",
    "    \n",
    "    # Compute error metrics\n",
    "    errors_trajectory_1.append(compute_errors(gt_depth_flat, pred_depth_flat))\n",
    "\n",
    "# Compute mean errors\n",
    "mean_errors = np.mean(errors_trajectory_1, axis=0)\n",
    "\n",
    "print(\"\\n  \" + (\"{:>8} | \" * 7).format(\"abs_rel\", \"sq_rel\", \"rmse\", \"rmse_log\", \"a1\", \"a2\", \"a3\"))\n",
    "print((\"{: 8.3f}  \" * 7).format(*mean_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_trajectory_1 = [item[2] for item in errors_trajectory_1]\n",
    "plt.title(\"RMSE as prediction horizon increases\")\n",
    "plt.plot(rmse_trajectory_1)\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trajectory 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code\n",
    "# INIT DEPTH PREDICTION\n",
    "min_depth = 0.1\n",
    "max_depth = 80\n",
    "\n",
    "height = 512\n",
    "width = 512\n",
    "batch_size = 1\n",
    "\n",
    "backproject_depth = BackprojectDepth(batch_size, height, width)\n",
    "project_3d = Project3D(batch_size, height, width)\n",
    "fraction_trajectory_2 = train_filenames[1733:1733+100]\n",
    "\n",
    "dataset = datasets.midair.MidAirDataset\n",
    "fpath = os.path.join(\"splits\", \"eigen_midair\", \"{}_files.txt\")\n",
    "data_path = \"MidAir\"\n",
    "\n",
    "print(\"Creating dataset trajectory 1\")\n",
    "dataset_trajectory_2 = dataset(\n",
    "    data_path, fraction_trajectory_2, \n",
    "    height, width,\n",
    "    [0, -1, 1],\n",
    "    select_file_names=True,\n",
    "    num_scales=1, \n",
    "    use_imu=True,\n",
    "    k_imu_clip=5, is_train=False, img_ext='.jpg' \n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "dataloader_trajectory_2 = DataLoader(dataset_trajectory_2, 1, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "list_frames_traj_2 = []\n",
    "list_gt_frames_traj_2 = []\n",
    "depth_gt_list = []  # List to store ground truth depth maps\n",
    "alpha, R_c, R_cbt_bc, delta_t, gravities, velocities = [], [], [], [], [], []\n",
    "\n",
    "avg_velocity = []\n",
    "\n",
    "for idx, sample in enumerate(dataset_trajectory_2):\n",
    "    # Standard processing\n",
    "    for key, ipt in sample.items():\n",
    "        if key in [(\"preint_imu\", -1, 0), (\"preint_imu\", 0, 1)]:\n",
    "            for pkey, pipt in sample[key].items():\n",
    "                sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                if pkey not in [\"v_norm\", \"delta_t\"]:\n",
    "                    pipt = pipt.unsqueeze(0)\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                else:\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "        else:\n",
    "            ipt = ipt.unsqueeze(0)\n",
    "            sample[key] = ipt.to(device, dtype=torch.float32)\n",
    "\n",
    "    if idx == 0:\n",
    "        init_sample = sample\n",
    "        init_image = sample[('color', 0, 0)]\n",
    "        disp_gt = sample[\"disp_gt\"]\n",
    "        depth_gt_init = (height // 2) / disp_gt.to(torch.float32)\n",
    "        depth_gt_init = torch.clamp(depth_gt_init, min_depth, max_depth)\n",
    "        depth_gt_init = depth_gt_init[:, 0].detach()\n",
    "\n",
    "    frames = sample[('color', 0, 0)]\n",
    "    disp_gt = sample[\"disp_gt\"]\n",
    "    disp_gt = (height // 2) / disp_gt.to(torch.float32)\n",
    "    disp_gt = torch.clamp(disp_gt, min_depth, max_depth)\n",
    "    depth_gt_sample = disp_gt[:, 0].detach()\n",
    "\n",
    "    # Store ground truth depth maps\n",
    "    depth_gt_list.append(depth_gt_sample.cpu())\n",
    "\n",
    "    # Collect frames for visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(10, 10), nrows=1, ncols=2)\n",
    "    frame_data = frames\n",
    "    im_2 = ax1.imshow(frame_data[0].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    im_3 = ax2.imshow(depth_gt_sample.permute(1, 2, 0).cpu().numpy(), cmap='viridis_r')\n",
    "    list_frames_traj_2.append(im_2)\n",
    "    list_gt_frames_traj_2.append(im_3)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Get IMU parameters\n",
    "    next_imu = sample[('preint_imu', -1, 0)]\n",
    "    alpha.append(next_imu[\"alpha\"])\n",
    "    R_c.append(next_imu[\"R_c\"])\n",
    "    R_cbt_bc.append(next_imu[\"R_cbt_bc\"])\n",
    "    delta_t.append(next_imu[\"delta_t\"])\n",
    "    avg_velocity.append(next_imu[\"v_norm\"])\n",
    "\n",
    "# Compute average velocity\n",
    "vel_2 = torch.mean(torch.stack(avg_velocity), dim=0)\n",
    "print(f\"Average velocity: {vel_2}\")\n",
    "\n",
    "# Add code to create video of the original trajectory\n",
    "image_frames_traj_2 = [im.get_array() for im in list_frames_traj_2]\n",
    "gt_frames_traj_2 = [im.get_array() for im in list_gt_frames_traj_2]\n",
    "\n",
    "# Create a figure and axis for the animation\n",
    "fig, ax = plt.subplots()\n",
    "# Initialize the image on the axis (using the first frame's shape)\n",
    "im = ax.imshow(image_frames_traj_2[0], cmap='viridis')\n",
    "\n",
    "# Update function for animation\n",
    "def update(frame):\n",
    "    im.set_data(frame)\n",
    "    return [im]\n",
    "\n",
    "# Create an animation\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, update, frames=image_frames_traj_2, interval=100, blit=True\n",
    ")\n",
    "\n",
    "# Save the animation as a video file (e.g., MP4)\n",
    "ani.save('Trajectories_anim/trajectory_2.mp4', writer='ffmpeg', fps=25)\n",
    "plt.close(fig)\n",
    "\n",
    "# Depth prediction using the same method as the second file\n",
    "TRANS_SCALE_FACTOR = 5.4\n",
    "pair_inputs = [init_sample[('color', 0, 0)], init_sample[('color', 1, 0)]]\n",
    "\n",
    "# Generate velocity and gravity inputs\n",
    "velo_inputs = [models[\"velo_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "gravity_inputs = [models[\"gravity_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "\n",
    "velocity = models[\"velo\"](velo_inputs)\n",
    "gravity = models[\"gravity\"](gravity_inputs)\n",
    "\n",
    "R_cbt_bc[0] = R_cbt_bc[0]\n",
    "\n",
    "# Get depth prediction\n",
    "with torch.no_grad():\n",
    "    output = models[\"depth\"](models[\"encoder\"](init_image))\n",
    "    disp_trajectory_2 = output\n",
    "\n",
    "# Adjusted depth prediction\n",
    "pred_disp, _ = disp_to_depth(disp_trajectory_2[(\"disp\", 0)], min_depth, max_depth)\n",
    "pred_disp = pred_disp.cpu()[:, 0]\n",
    "pred_depth = 1 / pred_disp\n",
    "\n",
    "# Apply median scaling\n",
    "ratio = np.median(depth_gt_init.cpu().numpy()) / np.median(pred_depth.cpu().numpy())\n",
    "pred_depth *= ratio\n",
    "pred_depth = pred_depth.to(init_image.device).unsqueeze(0)\n",
    "\n",
    "# Compute errors between predicted and ground truth depths\n",
    "##########################################################\n",
    "pred_depth_tmp = pred_depth.squeeze()\n",
    "pred_depth_tmp = pred_depth_tmp.detach().cpu().numpy()\n",
    "depth_gt_init_tmp = depth_gt_init.squeeze()\n",
    "depth_gt_init_tmp = depth_gt_init_tmp.detach().cpu().numpy()\n",
    "\n",
    "mask = (depth_gt_init_tmp > min_depth) & (depth_gt_init_tmp < max_depth)\n",
    "pred_depth_flat = pred_depth_tmp[mask]\n",
    "\n",
    "gt_depth_flat = depth_gt_init_tmp[mask]\n",
    "print(f\"init error : {compute_errors(gt_depth_flat, pred_depth_flat)[2]}\")\n",
    "##########################################################\n",
    "\n",
    "# Generate poses and depth trajectory\n",
    "poses_depth = get_poses_depth(dataset_trajectory_2, models, alpha, R_c, R_cbt_bc, delta_t, TRANS_SCALE_FACTOR)\n",
    "depth_after_imu, depth_init_trajectory_2, images_after_imu = get_depth_trajectory(\n",
    "    batch_size, init_image, pred_depth, poses_depth, init_sample\n",
    ")\n",
    "\n",
    "# Save depth video\n",
    "get_video_depth(depth_after_imu, \"Depth_anim/depth_trajectory_2.mp4\")\n",
    "\n",
    "# Function to compute errors\n",
    "def compute_errors(gt, pred):\n",
    "    \"\"\"Compute error metrics between predicted and ground truth depths.\"\"\"\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25     ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse = np.sqrt(((gt - pred) ** 2).mean())\n",
    "    rmse_log = np.sqrt(((np.log(gt) - np.log(pred)) ** 2).mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "    sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
    "\n",
    "    return abs_rel, sq_rel, rmse, rmse_log, a1, a2, a3\n",
    "\n",
    "# Now, compute errors between the predicted depth maps and ground truth\n",
    "# Collect predicted depth maps from depth_after_imu\n",
    "predicted_depth_maps = [depth.cpu().squeeze(0) for depth in depth_after_imu]\n",
    "\n",
    "errors_trajectory_2 = []\n",
    "\n",
    "for pred_depth_map, gt_depth_map in zip(predicted_depth_maps, depth_gt_list):\n",
    "    pred_depth_map_np = pred_depth_map.detach().numpy() \n",
    "    gt_depth_map_np = gt_depth_map.numpy()\n",
    "    \n",
    "    # Apply mask to valid depth values\n",
    "    mask = (gt_depth_map_np > min_depth) & (gt_depth_map_np < max_depth)\n",
    "    \n",
    "    pred_depth_flat = pred_depth_map_np[mask]\n",
    "    gt_depth_flat = gt_depth_map_np[mask]\n",
    "    \n",
    "    # Ensure predicted depths are within valid range\n",
    "    pred_depth_flat = np.clip(pred_depth_flat, min_depth, max_depth)\n",
    "    \n",
    "    # Compute error metrics\n",
    "    errors_trajectory_2.append(compute_errors(gt_depth_flat, pred_depth_flat))\n",
    "\n",
    "# Compute mean errors\n",
    "mean_errors = np.mean(errors_trajectory_2, axis=0)\n",
    "\n",
    "print(\"\\n  \" + (\"{:>8} | \" * 7).format(\"abs_rel\", \"sq_rel\", \"rmse\", \"rmse_log\", \"a1\", \"a2\", \"a3\"))\n",
    "print((\"{: 8.3f}  \" * 7).format(*mean_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_trajectory_2 = [item[2] for item in errors_trajectory_2]\n",
    "plt.title(\"RMSE as prediction horizon increases\")\n",
    "plt.plot(rmse_trajectory_2)\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('rmse_trajectories/rmse_trajectory_2.npy', rmse_trajectory_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"velocities/vel_2.npy\", vel_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trajectory 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code\n",
    "# INIT DEPTH PREDICTION\n",
    "min_depth = 0.1\n",
    "max_depth = 80\n",
    "\n",
    "height = 512\n",
    "width = 512\n",
    "batch_size = 1\n",
    "\n",
    "backproject_depth = BackprojectDepth(batch_size, height, width)\n",
    "project_3d = Project3D(batch_size, height, width)\n",
    "fraction_trajectory_3 = train_filenames[1833:1833+100]\n",
    "\n",
    "dataset = datasets.midair.MidAirDataset\n",
    "fpath = os.path.join(\"splits\", \"eigen_midair\", \"{}_files.txt\")\n",
    "data_path = \"MidAir\"\n",
    "\n",
    "print(\"Creating dataset trajectory 1\")\n",
    "dataset_trajectory_3 = dataset(\n",
    "    data_path, fraction_trajectory_3, \n",
    "    height, width,\n",
    "    [0, -1, 1],\n",
    "    select_file_names=True,\n",
    "    num_scales=1, \n",
    "    use_imu=True,\n",
    "    k_imu_clip=5, is_train=False, img_ext='.jpg' \n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "dataloader_trajectory_3 = DataLoader(dataset_trajectory_3, 1, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "list_frames_traj_3 = []\n",
    "list_gt_frames_traj_3 = []\n",
    "depth_gt_list = []  # List to store ground truth depth maps\n",
    "alpha, R_c, R_cbt_bc, delta_t, gravities, velocities = [], [], [], [], [], []\n",
    "\n",
    "avg_velocity = []\n",
    "\n",
    "for idx, sample in enumerate(dataset_trajectory_3):\n",
    "    # Standard processing\n",
    "    for key, ipt in sample.items():\n",
    "        if key in [(\"preint_imu\", -1, 0), (\"preint_imu\", 0, 1)]:\n",
    "            for pkey, pipt in sample[key].items():\n",
    "                sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                if pkey not in [\"v_norm\", \"delta_t\"]:\n",
    "                    pipt = pipt.unsqueeze(0)\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                else:\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "        else:\n",
    "            ipt = ipt.unsqueeze(0)\n",
    "            sample[key] = ipt.to(device, dtype=torch.float32)\n",
    "\n",
    "    if idx == 0:\n",
    "        init_sample = sample\n",
    "        init_image = sample[('color', 0, 0)]\n",
    "        depth_gt = sample[\"disp_gt\"]\n",
    "        depth_gt = (height // 2) / depth_gt.to(torch.float32)\n",
    "        depth_gt = torch.clamp(depth_gt, min_depth, max_depth)\n",
    "        depth_gt = depth_gt[:, 0].detach()\n",
    "\n",
    "    frames = sample[('color', 0, 0)]\n",
    "    disp_gt = sample[\"disp_gt\"]\n",
    "    disp_gt = (height // 2) / disp_gt.to(torch.float32)\n",
    "    disp_gt = torch.clamp(disp_gt, min_depth, max_depth)\n",
    "    depth_gt_sample = disp_gt[:, 0].detach()\n",
    "\n",
    "    # Store ground truth depth maps\n",
    "    depth_gt_list.append(depth_gt_sample.cpu())\n",
    "\n",
    "    # Collect frames for visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(10, 10), nrows=1, ncols=2)\n",
    "    frame_data = frames\n",
    "    im_3 = ax1.imshow(frame_data[0].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    im_4 = ax2.imshow(depth_gt_sample.permute(1, 2, 0).cpu().numpy(), cmap='viridis_r')\n",
    "    list_frames_traj_3.append(im_3)\n",
    "    list_gt_frames_traj_3.append(im_4)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Get IMU parameters\n",
    "    next_imu = sample[('preint_imu', -1, 0)]\n",
    "    alpha.append(next_imu[\"alpha\"])\n",
    "    R_c.append(next_imu[\"R_c\"])\n",
    "    R_cbt_bc.append(next_imu[\"R_cbt_bc\"])\n",
    "    delta_t.append(next_imu[\"delta_t\"])\n",
    "    avg_velocity.append(next_imu[\"v_norm\"])\n",
    "\n",
    "# Compute average velocity\n",
    "vel_3 = torch.mean(torch.stack(avg_velocity), dim=0)\n",
    "print(f\"Average velocity: {vel_3}\")\n",
    "\n",
    "# Add code to create video of the original trajectory\n",
    "image_frames_traj_3 = [im.get_array() for im in list_frames_traj_3]\n",
    "gt_frames_traj_3 = [im.get_array() for im in list_gt_frames_traj_3]\n",
    "\n",
    "# Create a figure and axis for the animation\n",
    "fig, ax = plt.subplots()\n",
    "# Initialize the image on the axis (using the first frame's shape)\n",
    "im = ax.imshow(image_frames_traj_3[0], cmap='viridis')\n",
    "\n",
    "# Update function for animation\n",
    "def update(frame):\n",
    "    im.set_data(frame)\n",
    "    return [im]\n",
    "\n",
    "# Create an animation\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, update, frames=image_frames_traj_3, interval=100, blit=True\n",
    ")\n",
    "\n",
    "# Save the animation as a video file (e.g., MP4)\n",
    "ani.save('Trajectories_anim/trajectory_3.mp4', writer='ffmpeg', fps=25)\n",
    "plt.close(fig)\n",
    "\n",
    "# Depth prediction using the same method as the second file\n",
    "TRANS_SCALE_FACTOR = 5.4\n",
    "pair_inputs = [init_sample[('color', 0, 0)], init_sample[('color', 1, 0)]]\n",
    "\n",
    "# Generate velocity and gravity inputs\n",
    "velo_inputs = [models[\"velo_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "gravity_inputs = [models[\"gravity_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "\n",
    "velocity = models[\"velo\"](velo_inputs)\n",
    "gravity = models[\"gravity\"](gravity_inputs)\n",
    "\n",
    "R_cbt_bc[0] = R_cbt_bc[0]\n",
    "\n",
    "# Get depth prediction\n",
    "with torch.no_grad():\n",
    "    output = models[\"depth\"](models[\"encoder\"](init_image))\n",
    "    disp_trajectory_3 = output\n",
    "\n",
    "# Adjusted depth prediction\n",
    "pred_disp, _ = disp_to_depth(disp_trajectory_3[(\"disp\", 0)], min_depth, max_depth)\n",
    "pred_disp = pred_disp.cpu()[:, 0]\n",
    "pred_depth = 1 / pred_disp\n",
    "\n",
    "# Apply median scaling\n",
    "ratio = np.median(depth_gt.cpu().numpy()) / np.median(pred_depth.cpu().numpy())\n",
    "pred_depth *= ratio\n",
    "pred_depth = pred_depth.to(init_image.device).unsqueeze(0)\n",
    "\n",
    "# Ensure depth values are within valid range\n",
    "pred_depth = torch.clamp(pred_depth, min_depth, max_depth)\n",
    "\n",
    "# Generate poses and depth trajectory\n",
    "poses_depth = get_poses_depth(dataset_trajectory_3, models, alpha, R_c, R_cbt_bc, delta_t, TRANS_SCALE_FACTOR)\n",
    "depth_after_imu, depth_init_trajectory_3, images_after_imu = get_depth_trajectory(\n",
    "    batch_size, init_image, disp_trajectory_3[(\"disp\", 0)], poses_depth, init_sample\n",
    ")\n",
    "\n",
    "# Save depth video\n",
    "get_video_depth(depth_after_imu, \"Depth_anim/depth_trajectory_3.mp4\")\n",
    "\n",
    "# Function to compute errors\n",
    "def compute_errors(gt, pred):\n",
    "    \"\"\"Compute error metrics between predicted and ground truth depths.\"\"\"\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25     ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse = np.sqrt(((gt - pred) ** 2).mean())\n",
    "    rmse_log = np.sqrt(((np.log(gt) - np.log(pred)) ** 2).mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "    sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
    "\n",
    "    return abs_rel, sq_rel, rmse, rmse_log, a1, a2, a3\n",
    "\n",
    "# Now, compute errors between the predicted depth maps and ground truth\n",
    "# Collect predicted depth maps from depth_after_imu\n",
    "predicted_depth_maps = [depth.cpu().squeeze(0) for depth in depth_after_imu]\n",
    "\n",
    "errors_trajectory_3 = []\n",
    "\n",
    "for pred_depth_map, gt_depth_map in zip(predicted_depth_maps, depth_gt_list):\n",
    "    pred_depth_map_np = pred_depth_map.detach().numpy() \n",
    "    gt_depth_map_np = gt_depth_map.numpy()\n",
    "    \n",
    "    # Apply mask to valid depth values\n",
    "    mask = (gt_depth_map_np > min_depth) & (gt_depth_map_np < max_depth)\n",
    "    \n",
    "    pred_depth_flat = pred_depth_map_np[mask]\n",
    "    gt_depth_flat = gt_depth_map_np[mask]\n",
    "    \n",
    "    # Ensure predicted depths are within valid range\n",
    "    pred_depth_flat = np.clip(pred_depth_flat, min_depth, max_depth)\n",
    "    \n",
    "    # Compute error metrics\n",
    "    errors_trajectory_3.append(compute_errors(gt_depth_flat, pred_depth_flat))\n",
    "\n",
    "# Compute mean errors\n",
    "mean_errors = np.mean(errors_trajectory_3, axis=0)\n",
    "\n",
    "print(\"\\n  \" + (\"{:>8} | \" * 7).format(\"abs_rel\", \"sq_rel\", \"rmse\", \"rmse_log\", \"a1\", \"a2\", \"a3\"))\n",
    "print((\"{: 8.3f}  \" * 7).format(*mean_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_trajectory_3 = [item[2] for item in errors_trajectory_3]\n",
    "plt.title(\"RMSE as prediction horizon increases\")\n",
    "plt.plot(rmse_trajectory_3)\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('rmse_trajectories/rmse_trajectory_3.npy', rmse_trajectory_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"velocities/vel_3.npy\", vel_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trajectory 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code\n",
    "# INIT DEPTH PREDICTION\n",
    "min_depth = 0.1\n",
    "max_depth = 80\n",
    "\n",
    "height = 512\n",
    "width = 512\n",
    "batch_size = 1\n",
    "\n",
    "backproject_depth = BackprojectDepth(batch_size, height, width)\n",
    "project_3d = Project3D(batch_size, height, width)\n",
    "fraction_trajectory_4 = train_filenames[9349:9349+100]\n",
    "\n",
    "dataset = datasets.midair.MidAirDataset\n",
    "fpath = os.path.join(\"splits\", \"eigen_midair\", \"{}_files.txt\")\n",
    "data_path = \"MidAir\"\n",
    "\n",
    "print(\"Creating dataset trajectory 1\")\n",
    "dataset_trajectory_4 = dataset(\n",
    "    data_path, fraction_trajectory_4, \n",
    "    height, width,\n",
    "    [0, -1, 1],\n",
    "    select_file_names=True,\n",
    "    num_scales=1, \n",
    "    use_imu=True,\n",
    "    k_imu_clip=5, is_train=False, img_ext='.jpg' \n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "dataloader_trajectory_4 = DataLoader(dataset_trajectory_4, 1, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "list_frames_traj_4 = []\n",
    "list_gt_frames_traj_4 = []\n",
    "depth_gt_list = []  # List to store ground truth depth maps\n",
    "alpha, R_c, R_cbt_bc, delta_t, gravities, velocities = [], [], [], [], [], []\n",
    "\n",
    "avg_velocity = []\n",
    "\n",
    "for idx, sample in enumerate(dataset_trajectory_4):\n",
    "    # Standard processing\n",
    "    for key, ipt in sample.items():\n",
    "        if key in [(\"preint_imu\", -1, 0), (\"preint_imu\", 0, 1)]:\n",
    "            for pkey, pipt in sample[key].items():\n",
    "                sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                if pkey not in [\"v_norm\", \"delta_t\"]:\n",
    "                    pipt = pipt.unsqueeze(0)\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                else:\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "        else:\n",
    "            ipt = ipt.unsqueeze(0)\n",
    "            sample[key] = ipt.to(device, dtype=torch.float32)\n",
    "\n",
    "    if idx == 0:\n",
    "        init_sample = sample\n",
    "        init_image = sample[('color', 0, 0)]\n",
    "        depth_gt = sample[\"disp_gt\"]\n",
    "        depth_gt = (height // 2) / depth_gt.to(torch.float32)\n",
    "        depth_gt = torch.clamp(depth_gt, min_depth, max_depth)\n",
    "        depth_gt = depth_gt[:, 0].detach()\n",
    "\n",
    "    frames = sample[('color', 0, 0)]\n",
    "    disp_gt = sample[\"disp_gt\"]\n",
    "    disp_gt = (height // 2) / disp_gt.to(torch.float32)\n",
    "    disp_gt = torch.clamp(disp_gt, min_depth, max_depth)\n",
    "    depth_gt_sample = disp_gt[:, 0].detach()\n",
    "\n",
    "    # Store ground truth depth maps\n",
    "    depth_gt_list.append(depth_gt_sample.cpu())\n",
    "\n",
    "    # Collect frames for visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(10, 10), nrows=1, ncols=2)\n",
    "    frame_data = frames\n",
    "    im_4 = ax1.imshow(frame_data[0].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    im_5 = ax2.imshow(depth_gt_sample.permute(1, 2, 0).cpu().numpy(), cmap='viridis_r')\n",
    "    list_frames_traj_4.append(im_4)\n",
    "    list_gt_frames_traj_4.append(im_5)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Get IMU parameters\n",
    "    next_imu = sample[('preint_imu', -1, 0)]\n",
    "    alpha.append(next_imu[\"alpha\"])\n",
    "    R_c.append(next_imu[\"R_c\"])\n",
    "    R_cbt_bc.append(next_imu[\"R_cbt_bc\"])\n",
    "    delta_t.append(next_imu[\"delta_t\"])\n",
    "    avg_velocity.append(next_imu[\"v_norm\"])\n",
    "\n",
    "# Compute average velocity\n",
    "vel_4 = torch.mean(torch.stack(avg_velocity), dim=0)\n",
    "print(f\"Average velocity: {vel_4}\")\n",
    "\n",
    "# Add code to create video of the original trajectory\n",
    "image_frames_traj_4 = [im.get_array() for im in list_frames_traj_4]\n",
    "gt_frames_traj_4 = [im.get_array() for im in list_gt_frames_traj_4]\n",
    "\n",
    "# Create a figure and axis for the animation\n",
    "fig, ax = plt.subplots()\n",
    "# Initialize the image on the axis (using the first frame's shape)\n",
    "im = ax.imshow(image_frames_traj_4[0], cmap='viridis')\n",
    "\n",
    "# Update function for animation\n",
    "def update(frame):\n",
    "    im.set_data(frame)\n",
    "    return [im]\n",
    "\n",
    "# Create an animation\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, update, frames=image_frames_traj_4, interval=100, blit=True\n",
    ")\n",
    "\n",
    "# Save the animation as a video file (e.g., MP4)\n",
    "ani.save('Trajectories_anim/trajectory_4.mp4', writer='ffmpeg', fps=25)\n",
    "plt.close(fig)\n",
    "\n",
    "# Depth prediction using the same method as the second file\n",
    "TRANS_SCALE_FACTOR = 5.4\n",
    "pair_inputs = [init_sample[('color', 0, 0)], init_sample[('color', 1, 0)]]\n",
    "\n",
    "# Generate velocity and gravity inputs\n",
    "velo_inputs = [models[\"velo_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "gravity_inputs = [models[\"gravity_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "\n",
    "velocity = models[\"velo\"](velo_inputs)\n",
    "gravity = models[\"gravity\"](gravity_inputs)\n",
    "\n",
    "R_cbt_bc[0] = R_cbt_bc[0]\n",
    "\n",
    "# Get depth prediction\n",
    "with torch.no_grad():\n",
    "    output = models[\"depth\"](models[\"encoder\"](init_image))\n",
    "    disp_trajectory_4 = output\n",
    "\n",
    "# Adjusted depth prediction\n",
    "pred_disp, _ = disp_to_depth(disp_trajectory_4[(\"disp\", 0)], min_depth, max_depth)\n",
    "pred_disp = pred_disp.cpu()[:, 0]\n",
    "pred_depth = 1 / pred_disp\n",
    "\n",
    "# Apply median scaling\n",
    "ratio = np.median(depth_gt.cpu().numpy()) / np.median(pred_depth.cpu().numpy())\n",
    "pred_depth *= ratio\n",
    "pred_depth = pred_depth.to(init_image.device).unsqueeze(0)\n",
    "\n",
    "# Ensure depth values are within valid range\n",
    "pred_depth = torch.clamp(pred_depth, min_depth, max_depth)\n",
    "\n",
    "# Generate poses and depth trajectory\n",
    "poses_depth = get_poses_depth(dataset_trajectory_4, models, alpha, R_c, R_cbt_bc, delta_t, TRANS_SCALE_FACTOR)\n",
    "depth_after_imu, depth_init_trajectory_4, images_after_imu = get_depth_trajectory(\n",
    "    batch_size, init_image, disp_trajectory_4[(\"disp\", 0)], poses_depth, init_sample\n",
    ")\n",
    "\n",
    "# Save depth video\n",
    "get_video_depth(depth_after_imu, \"Depth_anim/depth_trajectory_4.mp4\")\n",
    "\n",
    "# Function to compute errors\n",
    "def compute_errors(gt, pred):\n",
    "    \"\"\"Compute error metrics between predicted and ground truth depths.\"\"\"\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25     ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse_trajectory_4 = np.sqrt(((gt - pred) ** 2).mean())\n",
    "    rmse_log = np.sqrt(((np.log(gt) - np.log(pred)) ** 2).mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "    sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
    "\n",
    "    return abs_rel, sq_rel, rmse_trajectory_4, rmse_log, a1, a2, a3\n",
    "\n",
    "# Now, compute errors between the predicted depth maps and ground truth\n",
    "# Collect predicted depth maps from depth_after_imu\n",
    "predicted_depth_maps = [depth.cpu().squeeze(0) for depth in depth_after_imu]\n",
    "\n",
    "errors_trajectory_4 = []\n",
    "\n",
    "for pred_depth_map, gt_depth_map in zip(predicted_depth_maps, depth_gt_list):\n",
    "    pred_depth_map_np = pred_depth_map.detach().numpy() \n",
    "    gt_depth_map_np = gt_depth_map.numpy()\n",
    "    \n",
    "    # Apply mask to valid depth values\n",
    "    mask = (gt_depth_map_np > min_depth) & (gt_depth_map_np < max_depth)\n",
    "    \n",
    "    pred_depth_flat = pred_depth_map_np[mask]\n",
    "    gt_depth_flat = gt_depth_map_np[mask]\n",
    "    \n",
    "    # Ensure predicted depths are within valid range\n",
    "    pred_depth_flat = np.clip(pred_depth_flat, min_depth, max_depth)\n",
    "    \n",
    "    # Compute error metrics\n",
    "    errors_trajectory_4.append(compute_errors(gt_depth_flat, pred_depth_flat))\n",
    "\n",
    "# Compute mean errors\n",
    "mean_errors = np.mean(errors_trajectory_4, axis=0)\n",
    "\n",
    "print(\"\\n  \" + (\"{:>8} | \" * 7).format(\"abs_rel\", \"sq_rel\", \"rmse_trajectory_4\", \"rmse_log\", \"a1\", \"a2\", \"a3\"))\n",
    "print((\"{: 8.3f}  \" * 7).format(*mean_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_trajectory_4 = [item[2] for item in errors_trajectory_4]\n",
    "plt.title(\"RMSE as prediction horizon increases\")\n",
    "plt.plot(rmse_trajectory_4)\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trajectory 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code\n",
    "# INIT DEPTH PREDICTION\n",
    "min_depth = 0.1\n",
    "max_depth = 80\n",
    "\n",
    "height = 512\n",
    "width = 512\n",
    "batch_size = 1\n",
    "\n",
    "backproject_depth = BackprojectDepth(batch_size, height, width)\n",
    "project_3d = Project3D(batch_size, height, width)\n",
    "fraction_trajectory_5 = train_filenames[9632:9632+100]\n",
    "\n",
    "dataset = datasets.midair.MidAirDataset\n",
    "fpath = os.path.join(\"splits\", \"eigen_midair\", \"{}_files.txt\")\n",
    "data_path = \"MidAir\"\n",
    "\n",
    "print(\"Creating dataset trajectory 1\")\n",
    "dataset_trajectory_5 = dataset(\n",
    "    data_path, fraction_trajectory_5, \n",
    "    height, width,\n",
    "    [0, -1, 1],\n",
    "    select_file_names=True,\n",
    "    num_scales=1, \n",
    "    use_imu=True,\n",
    "    k_imu_clip=5, is_train=False, img_ext='.jpg' \n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "dataloader_trajectory_5 = DataLoader(dataset_trajectory_5, 1, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "list_frames_traj_5 = []\n",
    "list_gt_frames_traj_5 = []\n",
    "depth_gt_list = []  # List to store ground truth depth maps\n",
    "alpha, R_c, R_cbt_bc, delta_t, gravities, velocities = [], [], [], [], [], []\n",
    "\n",
    "avg_velocity = []\n",
    "\n",
    "for idx, sample in enumerate(dataset_trajectory_5):\n",
    "    # Standard processing\n",
    "    for key, ipt in sample.items():\n",
    "        if key in [(\"preint_imu\", -1, 0), (\"preint_imu\", 0, 1)]:\n",
    "            for pkey, pipt in sample[key].items():\n",
    "                sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                if pkey not in [\"v_norm\", \"delta_t\"]:\n",
    "                    pipt = pipt.unsqueeze(0)\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                else:\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "        else:\n",
    "            ipt = ipt.unsqueeze(0)\n",
    "            sample[key] = ipt.to(device, dtype=torch.float32)\n",
    "\n",
    "    if idx == 0:\n",
    "        init_sample = sample\n",
    "        init_image = sample[('color', 0, 0)]\n",
    "        depth_gt = sample[\"disp_gt\"]\n",
    "        depth_gt = (height // 2) / depth_gt.to(torch.float32)\n",
    "        depth_gt = torch.clamp(depth_gt, min_depth, max_depth)\n",
    "        depth_gt = depth_gt[:, 0].detach()\n",
    "\n",
    "    frames = sample[('color', 0, 0)]\n",
    "    disp_gt = sample[\"disp_gt\"]\n",
    "    disp_gt = (height // 2) / disp_gt.to(torch.float32)\n",
    "    disp_gt = torch.clamp(disp_gt, min_depth, max_depth)\n",
    "    depth_gt_sample = disp_gt[:, 0].detach()\n",
    "\n",
    "    # Store ground truth depth maps\n",
    "    depth_gt_list.append(depth_gt_sample.cpu())\n",
    "\n",
    "    # Collect frames for visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(10, 10), nrows=1, ncols=2)\n",
    "    frame_data = frames\n",
    "    im_5 = ax1.imshow(frame_data[0].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    im_6 = ax2.imshow(depth_gt_sample.permute(1, 2, 0).cpu().numpy(), cmap='viridis_r')\n",
    "    list_frames_traj_5.append(im_5)\n",
    "    list_gt_frames_traj_5.append(im_6)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Get IMU parameters\n",
    "    next_imu = sample[('preint_imu', -1, 0)]\n",
    "    alpha.append(next_imu[\"alpha\"])\n",
    "    R_c.append(next_imu[\"R_c\"])\n",
    "    R_cbt_bc.append(next_imu[\"R_cbt_bc\"])\n",
    "    delta_t.append(next_imu[\"delta_t\"])\n",
    "    avg_velocity.append(next_imu[\"v_norm\"])\n",
    "\n",
    "# Compute average velocity\n",
    "vel_5 = torch.mean(torch.stack(avg_velocity), dim=0)\n",
    "print(f\"Average velocity: {vel_5}\")\n",
    "\n",
    "# Add code to create video of the original trajectory\n",
    "image_frames_traj_5 = [im.get_array() for im in list_frames_traj_5]\n",
    "gt_frames_traj_5 = [im.get_array() for im in list_gt_frames_traj_5]\n",
    "\n",
    "# Create a figure and axis for the animation\n",
    "fig, ax = plt.subplots()\n",
    "# Initialize the image on the axis (using the first frame's shape)\n",
    "im = ax.imshow(image_frames_traj_5[0], cmap='viridis')\n",
    "\n",
    "# Update function for animation\n",
    "def update(frame):\n",
    "    im.set_data(frame)\n",
    "    return [im]\n",
    "\n",
    "# Create an animation\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, update, frames=image_frames_traj_5, interval=100, blit=True\n",
    ")\n",
    "\n",
    "# Save the animation as a video file (e.g., MP4)\n",
    "ani.save('Trajectories_anim/trajectory_5.mp4', writer='ffmpeg', fps=25)\n",
    "plt.close(fig)\n",
    "\n",
    "# Depth prediction using the same method as the second file\n",
    "TRANS_SCALE_FACTOR = 5.4\n",
    "pair_inputs = [init_sample[('color', 0, 0)], init_sample[('color', 1, 0)]]\n",
    "\n",
    "# Generate velocity and gravity inputs\n",
    "velo_inputs = [models[\"velo_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "gravity_inputs = [models[\"gravity_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "\n",
    "velocity = models[\"velo\"](velo_inputs)\n",
    "gravity = models[\"gravity\"](gravity_inputs)\n",
    "\n",
    "R_cbt_bc[0] = R_cbt_bc[0]\n",
    "\n",
    "# Get depth prediction\n",
    "with torch.no_grad():\n",
    "    output = models[\"depth\"](models[\"encoder\"](init_image))\n",
    "    disp_trajectory_5 = output\n",
    "\n",
    "# Adjusted depth prediction\n",
    "pred_disp, _ = disp_to_depth(disp_trajectory_5[(\"disp\", 0)], min_depth, max_depth)\n",
    "pred_disp = pred_disp.cpu()[:, 0]\n",
    "pred_depth = 1 / pred_disp\n",
    "\n",
    "# Apply median scaling\n",
    "ratio = np.median(depth_gt.cpu().numpy()) / np.median(pred_depth.cpu().numpy())\n",
    "pred_depth *= ratio\n",
    "pred_depth = pred_depth.to(init_image.device).unsqueeze(0)\n",
    "\n",
    "# Ensure depth values are within valid range\n",
    "pred_depth = torch.clamp(pred_depth, min_depth, max_depth)\n",
    "\n",
    "# Generate poses and depth trajectory\n",
    "poses_depth = get_poses_depth(dataset_trajectory_5, models, alpha, R_c, R_cbt_bc, delta_t, TRANS_SCALE_FACTOR)\n",
    "depth_after_imu, depth_init_trajectory_5, images_after_imu = get_depth_trajectory(\n",
    "    batch_size, init_image, disp_trajectory_5[(\"disp\", 0)], poses_depth, init_sample\n",
    ")\n",
    "\n",
    "# Save depth video\n",
    "get_video_depth(depth_after_imu, \"Depth_anim/depth_trajectory_5.mp4\")\n",
    "\n",
    "# Function to compute errors\n",
    "def compute_errors(gt, pred):\n",
    "    \"\"\"Compute error metrics between predicted and ground truth depths.\"\"\"\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25     ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse_trajectory_5 = np.sqrt(((gt - pred) ** 2).mean())\n",
    "    rmse_log = np.sqrt(((np.log(gt) - np.log(pred)) ** 2).mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "    sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
    "\n",
    "    return abs_rel, sq_rel, rmse_trajectory_5, rmse_log, a1, a2, a3\n",
    "\n",
    "# Now, compute errors between the predicted depth maps and ground truth\n",
    "# Collect predicted depth maps from depth_after_imu\n",
    "predicted_depth_maps = [depth.cpu().squeeze(0) for depth in depth_after_imu]\n",
    "\n",
    "errors_trajectory_5 = []\n",
    "\n",
    "for pred_depth_map, gt_depth_map in zip(predicted_depth_maps, depth_gt_list):\n",
    "    pred_depth_map_np = pred_depth_map.detach().numpy() \n",
    "    gt_depth_map_np = gt_depth_map.numpy()\n",
    "    \n",
    "    # Apply mask to valid depth values\n",
    "    mask = (gt_depth_map_np > min_depth) & (gt_depth_map_np < max_depth)\n",
    "    \n",
    "    pred_depth_flat = pred_depth_map_np[mask]\n",
    "    gt_depth_flat = gt_depth_map_np[mask]\n",
    "    \n",
    "    # Ensure predicted depths are within valid range\n",
    "    pred_depth_flat = np.clip(pred_depth_flat, min_depth, max_depth)\n",
    "    \n",
    "    # Compute error metrics\n",
    "    errors_trajectory_5.append(compute_errors(gt_depth_flat, pred_depth_flat))\n",
    "\n",
    "# Compute mean errors\n",
    "mean_errors = np.mean(errors_trajectory_5, axis=0)\n",
    "\n",
    "print(\"\\n  \" + (\"{:>8} | \" * 7).format(\"abs_rel\", \"sq_rel\", \"rmse_trajectory_5\", \"rmse_log\", \"a1\", \"a2\", \"a3\"))\n",
    "print((\"{: 8.3f}  \" * 7).format(*mean_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_trajectory_5 = [item[2] for item in errors_trajectory_5]\n",
    "plt.title(\"RMSE as prediction horizon increases\")\n",
    "plt.plot(rmse_trajectory_5)\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trajectory 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.midair.MidAirDataset\n",
    "\n",
    "fpath = os.path.join(\"splits\",\"eigen_midair\", \"{}_files.txt\")\n",
    "train_filenames = readlines(fpath.format(\"test\"))\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code\n",
    "# INIT DEPTH PREDICTION\n",
    "min_depth = 0.1\n",
    "max_depth = 80\n",
    "\n",
    "height = 512\n",
    "width = 512\n",
    "batch_size = 1\n",
    "\n",
    "backproject_depth = BackprojectDepth(batch_size, height, width)\n",
    "project_3d = Project3D(batch_size, height, width)\n",
    "fraction_trajectory_6 = train_filenames[9684:9684+100]\n",
    "\n",
    "dataset = datasets.midair.MidAirDataset\n",
    "fpath = os.path.join(\"splits\", \"eigen_midair\", \"{}_files.txt\")\n",
    "data_path = \"MidAir\"\n",
    "\n",
    "print(\"Creating dataset trajectory 1\")\n",
    "dataset_trajectory_6 = dataset(\n",
    "    data_path, fraction_trajectory_6, \n",
    "    height, width,\n",
    "    [0, -1, 1],\n",
    "    select_file_names=True,\n",
    "    num_scales=1, \n",
    "    use_imu=True,\n",
    "    k_imu_clip=5, is_train=False, img_ext='.jpg' \n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "dataloader_trajectory_6 = DataLoader(dataset_trajectory_6, 1, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "list_frames_traj_6 = []\n",
    "list_gt_frames_traj_6 = []\n",
    "depth_gt_list = []  # List to store ground truth depth maps\n",
    "alpha, R_c, R_cbt_bc, delta_t, gravities, velocities = [], [], [], [], [], []\n",
    "\n",
    "avg_velocity = []\n",
    "\n",
    "for idx, sample in enumerate(dataset_trajectory_6):\n",
    "    # Standard processing\n",
    "    for key, ipt in sample.items():\n",
    "        if key in [(\"preint_imu\", -1, 0), (\"preint_imu\", 0, 1)]:\n",
    "            for pkey, pipt in sample[key].items():\n",
    "                sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                if pkey not in [\"v_norm\", \"delta_t\"]:\n",
    "                    pipt = pipt.unsqueeze(0)\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                else:\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "        else:\n",
    "            ipt = ipt.unsqueeze(0)\n",
    "            sample[key] = ipt.to(device, dtype=torch.float32)\n",
    "\n",
    "    if idx == 0:\n",
    "        init_sample = sample\n",
    "        init_image = sample[('color', 0, 0)]\n",
    "        disp_gt_batch = sample[\"disp_gt\"]\n",
    "        depth_gt_init = (height // 2) / disp_gt_batch.to(torch.float32)\n",
    "        depth_gt_init = torch.clamp(depth_gt_init, min_depth, max_depth)\n",
    "        depth_gt_init = depth_gt_init[:, 0].detach()\n",
    "\n",
    "    frames = sample[('color', 0, 0)]\n",
    "    disp_gt = sample[\"disp_gt\"]\n",
    "    disp_gt = (height // 2) / disp_gt.to(torch.float32)\n",
    "    disp_gt = torch.clamp(disp_gt, min_depth, max_depth)\n",
    "    depth_gt_sample = disp_gt[:, 0].detach()\n",
    "\n",
    "    # Store ground truth depth maps\n",
    "    depth_gt_list.append(depth_gt_sample.cpu())\n",
    "\n",
    "    # Collect frames for visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(10, 10), nrows=1, ncols=2)\n",
    "    frame_data = frames\n",
    "    im_6 = ax1.imshow(frame_data[0].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    im_7 = ax2.imshow(depth_gt_sample.permute(1, 2, 0).cpu().numpy(), cmap='viridis_r')\n",
    "    list_frames_traj_6.append(im_6)\n",
    "    list_gt_frames_traj_6.append(im_7)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Get IMU parameters\n",
    "    next_imu = sample[('preint_imu', -1, 0)]\n",
    "    alpha.append(next_imu[\"alpha\"])\n",
    "    R_c.append(next_imu[\"R_c\"])\n",
    "    R_cbt_bc.append(next_imu[\"R_cbt_bc\"])\n",
    "    delta_t.append(next_imu[\"delta_t\"])\n",
    "    avg_velocity.append(next_imu[\"v_norm\"])\n",
    "\n",
    "# Compute average velocity\n",
    "vel_6 = torch.mean(torch.stack(avg_velocity), dim=0)\n",
    "print(f\"Average velocity: {vel_6}\")\n",
    "\n",
    "# Add code to create video of the original trajectory\n",
    "image_frames_traj_6 = [im.get_array() for im in list_frames_traj_6]\n",
    "gt_frames_traj_6 = [im.get_array() for im in list_gt_frames_traj_6]\n",
    "\n",
    "# Create a figure and axis for the animation\n",
    "fig, ax = plt.subplots()\n",
    "# Initialize the image on the axis (using the first frame's shape)\n",
    "im = ax.imshow(image_frames_traj_6[0], cmap='viridis')\n",
    "\n",
    "# Update function for animation\n",
    "def update(frame):\n",
    "    im.set_data(frame)\n",
    "    return [im]\n",
    "\n",
    "# Create an animation\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, update, frames=image_frames_traj_6, interval=100, blit=True\n",
    ")\n",
    "\n",
    "# Save the animation as a video file (e.g., MP4)\n",
    "ani.save('Trajectories_anim/trajectory_6.mp4', writer='ffmpeg', fps=25)\n",
    "plt.close(fig)\n",
    "\n",
    "# Depth prediction using the same method as the second file\n",
    "TRANS_SCALE_FACTOR = 5.4\n",
    "pair_inputs = [init_sample[('color', 0, 0)], init_sample[('color', 1, 0)]]\n",
    "\n",
    "# Generate velocity and gravity inputs\n",
    "velo_inputs = [models[\"velo_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "gravity_inputs = [models[\"gravity_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "\n",
    "velocity = models[\"velo\"](velo_inputs)\n",
    "gravity = models[\"gravity\"](gravity_inputs)\n",
    "\n",
    "R_cbt_bc[0] = R_cbt_bc[0]\n",
    "\n",
    "# Get depth prediction\n",
    "with torch.no_grad():\n",
    "    output = models[\"depth\"](models[\"encoder\"](init_image))\n",
    "    disp_trajectory_6 = output\n",
    "\n",
    "# Adjusted depth prediction\n",
    "pred_disp, _ = disp_to_depth(disp_trajectory_6[(\"disp\", 0)], min_depth, max_depth)\n",
    "pred_disp = pred_disp.cpu()[:, 0]\n",
    "pred_depth = 1 / pred_disp\n",
    "\n",
    "# Apply median scaling\n",
    "ratio = np.median(depth_gt_init.cpu().numpy()) / np.median(pred_depth.cpu().numpy())\n",
    "pred_depth *= ratio\n",
    "pred_depth = pred_depth.to(init_image.device).unsqueeze(0)\n",
    "\n",
    "# Compute errors between predicted and ground truth depths\n",
    "##########################################################\n",
    "pred_depth_tmp = pred_depth.squeeze()\n",
    "pred_depth_tmp = pred_depth_tmp.detach().cpu().numpy()\n",
    "depth_gt_init_tmp = depth_gt_init.squeeze()\n",
    "depth_gt_init_tmp = depth_gt_init_tmp.detach().cpu().numpy()\n",
    "\n",
    "mask = (depth_gt_init_tmp > min_depth) & (depth_gt_init_tmp < max_depth)\n",
    "pred_depth_flat = pred_depth_tmp[mask]\n",
    "\n",
    "gt_depth_flat = depth_gt_init_tmp[mask]\n",
    "print(f\"init error : {compute_errors(gt_depth_flat, pred_depth_flat)[2]}\")\n",
    "##########################################################\n",
    "\n",
    "\n",
    "# Generate poses and depth trajectory\n",
    "poses_depth = get_poses_depth(dataset_trajectory_6, models, alpha, R_c, R_cbt_bc, delta_t, TRANS_SCALE_FACTOR)\n",
    "depth_after_imu, depth_init_trajectory_6, images_after_imu = get_depth_trajectory(\n",
    "    batch_size, init_image, pred_depth, poses_depth, init_sample\n",
    ")\n",
    "\n",
    "# Save depth video\n",
    "get_video_depth(depth_after_imu, \"Depth_anim/depth_trajectory_6_2.mp4\")\n",
    "\n",
    "# Function to compute errors\n",
    "def compute_errors(gt, pred):\n",
    "    \"\"\"Compute error metrics between predicted and ground truth depths.\"\"\"\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25     ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse_trajectory_6 = np.sqrt(((gt - pred) ** 2).mean())\n",
    "    rmse_log = np.sqrt(((np.log(gt) - np.log(pred)) ** 2).mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "    sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
    "\n",
    "    return abs_rel, sq_rel, rmse_trajectory_6, rmse_log, a1, a2, a3\n",
    "\n",
    "# Now, compute errors between the predicted depth maps and ground truth\n",
    "# Collect predicted depth maps from depth_after_imu\n",
    "predicted_depth_maps = [depth.cpu().squeeze(0) for depth in depth_after_imu]\n",
    "\n",
    "errors_trajectory_6 = []\n",
    "\n",
    "for pred_depth_map, gt_depth_map in zip(predicted_depth_maps, depth_gt_list):\n",
    "    pred_depth_map_np = pred_depth_map.detach().numpy() \n",
    "    gt_depth_map_np = gt_depth_map.numpy()\n",
    "    \n",
    "    # Apply mask to valid depth values\n",
    "    mask = (gt_depth_map_np > min_depth) & (gt_depth_map_np < max_depth)\n",
    "    \n",
    "    pred_depth_flat = pred_depth_map_np[mask]\n",
    "    gt_depth_flat = gt_depth_map_np[mask]\n",
    "    \n",
    "    # Ensure predicted depths are within valid range\n",
    "    pred_depth_flat = np.clip(pred_depth_flat, min_depth, max_depth)\n",
    "    \n",
    "    # Compute error metrics\n",
    "    errors_trajectory_6.append(compute_errors(gt_depth_flat, pred_depth_flat))\n",
    "\n",
    "# Compute mean errors\n",
    "mean_errors = np.mean(errors_trajectory_6, axis=0)\n",
    "\n",
    "print(\"\\n  \" + (\"{:>8} | \" * 7).format(\"abs_rel\", \"sq_rel\", \"rmse_trajectory_6\", \"rmse_log\", \"a1\", \"a2\", \"a3\"))\n",
    "print((\"{: 8.3f}  \" * 7).format(*mean_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_trajectory_6 = [item[2] for item in errors_trajectory_6]\n",
    "plt.title(\"RMSE as prediction horizon increases\")\n",
    "plt.plot(rmse_trajectory_6)\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('rmse_trajectories/rmse_trajectory_6.npy', rmse_trajectory_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"velocities/vel_6.npy\", vel_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"000000.png\"\n",
    "idx2 = [0,5,10,15,20,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100]\n",
    "for i in range(len(image_frames_traj_6)):\n",
    "    if i in idx2:\n",
    "        image = image_frames_traj_6[i]\n",
    "        save_file = file_name.split(\".\")[0] + f\"_{i}.png\"\n",
    "        plt.imshow(image)\n",
    "        plt.imsave(f\"/Users/ibrahimhassan/Documents/Documents/thesis_DynaDepth/Report_images_1/{save_file}\",image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"100000.png\"\n",
    "for i in range(len(depth_after_imu)):\n",
    "    if i in idx2:\n",
    "        image = depth_after_imu[i][0]\n",
    "        save_file = file_name.split(\".\")[0] + f\"_{i}.png\"\n",
    "        print(image.permute(1,2,0).detach().numpy().shape)\n",
    "        plt.imshow(image.permute(1,2,0).detach().numpy())\n",
    "        plt.imsave(f\"/Users/ibrahimhassan/Documents/Documents/thesis_DynaDepth/Report_images_1/{save_file}\",image.squeeze().detach().numpy(), cmap='viridis')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trajectory 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(\"splits\", \"eigen_midair\", \"{}_files.txt\"))\n",
    "fpath = os.path.join(\"splits\",\"eigen_midair\", \"{}_files.txt\")\n",
    "\n",
    "train_filenames = readlines(fpath.format(\"train\"))\n",
    "\n",
    "train_filenames = sorted(train_filenames, key=custom_sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code\n",
    "# INIT DEPTH PREDICTION\n",
    "min_depth = 0.1\n",
    "max_depth = 80\n",
    "\n",
    "height = 512\n",
    "width = 512\n",
    "batch_size = 1\n",
    "\n",
    "backproject_depth = BackprojectDepth(batch_size, height, width)\n",
    "project_3d = Project3D(batch_size, height, width)\n",
    "fraction_trajectory_7 = train_filenames[25588:25588+100]\n",
    "\n",
    "dataset = datasets.midair.MidAirDataset\n",
    "fpath = os.path.join(\"splits\", \"eigen_midair\", \"{}_files.txt\")\n",
    "data_path = \"MidAir\"\n",
    "\n",
    "print(\"Creating dataset trajectory 1\")\n",
    "dataset_trajectory_7 = dataset(\n",
    "    data_path, fraction_trajectory_7, \n",
    "    height, width,\n",
    "    [0, -1, 1],\n",
    "    select_file_names=True,\n",
    "    num_scales=1, \n",
    "    use_imu=True,\n",
    "    k_imu_clip=5, is_train=False, img_ext='.jpg' \n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "dataloader_trajectory_7 = DataLoader(dataset_trajectory_7, 1, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "list_frames_traj_7 = []\n",
    "list_gt_frames_traj_7 = []\n",
    "depth_gt_list = []  # List to store ground truth depth maps\n",
    "alpha, R_c, R_cbt_bc, delta_t, gravities, velocities = [], [], [], [], [], []\n",
    "\n",
    "avg_velocity = []\n",
    "\n",
    "for idx, sample in enumerate(dataset_trajectory_7):\n",
    "    # Standard processing\n",
    "    for key, ipt in sample.items():\n",
    "        if key in [(\"preint_imu\", -1, 0), (\"preint_imu\", 0, 1)]:\n",
    "            for pkey, pipt in sample[key].items():\n",
    "                sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                if pkey not in [\"v_norm\", \"delta_t\"]:\n",
    "                    pipt = pipt.unsqueeze(0)\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                else:\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "        else:\n",
    "            ipt = ipt.unsqueeze(0)\n",
    "            sample[key] = ipt.to(device, dtype=torch.float32)\n",
    "\n",
    "    if idx == 0:\n",
    "        init_sample = sample\n",
    "        init_image = sample[('color', 0, 0)]\n",
    "        disp_gt_batch = sample[\"disp_gt\"]\n",
    "        depth_gt_init = (height // 2) / disp_gt_batch.to(torch.float32)\n",
    "        depth_gt_init = torch.clamp(depth_gt_init, min_depth, max_depth)\n",
    "        depth_gt_init = depth_gt_init[:, 0].detach()\n",
    "\n",
    "    frames = sample[('color', 0, 0)]\n",
    "    disp_gt = sample[\"disp_gt\"]\n",
    "    disp_gt = (height // 2) / disp_gt.to(torch.float32)\n",
    "    disp_gt = torch.clamp(disp_gt, min_depth, max_depth)\n",
    "    depth_gt_sample = disp_gt[:, 0].detach()\n",
    "\n",
    "    # Store ground truth depth maps\n",
    "    depth_gt_list.append(depth_gt_sample.cpu())\n",
    "\n",
    "    # Collect frames for visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(10, 10), nrows=1, ncols=2)\n",
    "    frame_data = frames\n",
    "    im_7 = ax1.imshow(frame_data[0].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    im_8 = ax2.imshow(depth_gt_sample.permute(1, 2, 0).cpu().numpy(), cmap='viridis_r')\n",
    "    list_frames_traj_7.append(im_7)\n",
    "    list_gt_frames_traj_7.append(im_8)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Get IMU parameters\n",
    "    next_imu = sample[('preint_imu', -1, 0)]\n",
    "    alpha.append(next_imu[\"alpha\"])\n",
    "    R_c.append(next_imu[\"R_c\"])\n",
    "    R_cbt_bc.append(next_imu[\"R_cbt_bc\"])\n",
    "    delta_t.append(next_imu[\"delta_t\"])\n",
    "    avg_velocity.append(next_imu[\"v_norm\"])\n",
    "\n",
    "# Compute average velocity\n",
    "vel_7 = torch.mean(torch.stack(avg_velocity), dim=0)\n",
    "print(f\"Average velocity: {vel_7}\")\n",
    "\n",
    "# Add code to create video of the original trajectory\n",
    "image_frames_traj_7 = [im.get_array() for im in list_frames_traj_7]\n",
    "gt_frames_traj_7 = [im.get_array() for im in list_gt_frames_traj_7]\n",
    "\n",
    "# Create a figure and axis for the animation\n",
    "fig, ax = plt.subplots()\n",
    "# Initialize the image on the axis (using the first frame's shape)\n",
    "im = ax.imshow(image_frames_traj_7[0], cmap='viridis')\n",
    "\n",
    "# Update function for animation\n",
    "def update(frame):\n",
    "    im.set_data(frame)\n",
    "    return [im]\n",
    "\n",
    "# Create an animation\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, update, frames=image_frames_traj_7, interval=100, blit=True\n",
    ")\n",
    "\n",
    "# Save the animation as a video file (e.g., MP4)\n",
    "ani.save('Trajectories_anim/trajectory_7.mp4', writer='ffmpeg', fps=25)\n",
    "plt.close(fig)\n",
    "\n",
    "# Depth prediction using the same method as the second file\n",
    "TRANS_SCALE_FACTOR = 5.4\n",
    "pair_inputs = [init_sample[('color', 0, 0)], init_sample[('color', 1, 0)]]\n",
    "\n",
    "# Generate velocity and gravity inputs\n",
    "velo_inputs = [models[\"velo_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "gravity_inputs = [models[\"gravity_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "\n",
    "velocity = models[\"velo\"](velo_inputs)\n",
    "gravity = models[\"gravity\"](gravity_inputs)\n",
    "\n",
    "R_cbt_bc[0] = R_cbt_bc[0]\n",
    "\n",
    "# Get depth prediction\n",
    "with torch.no_grad():\n",
    "    output = models[\"depth\"](models[\"encoder\"](init_image))\n",
    "    disp_trajectory_7 = output\n",
    "\n",
    "# Adjusted depth prediction\n",
    "pred_disp, _ = disp_to_depth(disp_trajectory_7[(\"disp\", 0)], min_depth, max_depth)\n",
    "pred_disp = pred_disp.cpu()[:, 0]\n",
    "pred_depth = 1 / pred_disp\n",
    "\n",
    "# Apply median scaling\n",
    "ratio = np.median(depth_gt_init.cpu().numpy()) / np.median(pred_depth.cpu().numpy())\n",
    "pred_depth *= ratio\n",
    "pred_depth = pred_depth.to(init_image.device).unsqueeze(0)\n",
    "\n",
    "\n",
    "# Compute errors between predicted and ground truth depths\n",
    "##########################################################\n",
    "pred_depth_tmp = pred_depth.squeeze()\n",
    "pred_depth_tmp = pred_depth_tmp.detach().cpu().numpy()\n",
    "depth_gt_init_tmp = depth_gt_init.squeeze()\n",
    "depth_gt_init_tmp = depth_gt_init_tmp.detach().cpu().numpy()\n",
    "\n",
    "mask = (depth_gt_init_tmp > min_depth) & (depth_gt_init_tmp < max_depth)\n",
    "pred_depth_flat = pred_depth_tmp[mask]\n",
    "\n",
    "gt_depth_flat = depth_gt_init_tmp[mask]\n",
    "print(f\"init error : {compute_errors(gt_depth_flat, pred_depth_flat)[2]}\")\n",
    "##########################################################\n",
    "\n",
    "# Generate poses and depth trajectory\n",
    "poses_depth = get_poses_depth(dataset_trajectory_7, models, alpha, R_c, R_cbt_bc, delta_t, TRANS_SCALE_FACTOR)\n",
    "depth_after_imu, depth_init_trajectory_7, images_after_imu = get_depth_trajectory(\n",
    "    batch_size, init_image,pred_depth, poses_depth, init_sample\n",
    ")\n",
    "\n",
    "# Save depth video\n",
    "get_video_depth(depth_after_imu, \"Depth_anim/depth_trajectory_7.mp4\")\n",
    "\n",
    "# Function to compute errors\n",
    "def compute_errors(gt, pred):\n",
    "    \"\"\"Compute error metrics between predicted and ground truth depths.\"\"\"\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25     ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse_trajectory_7 = np.sqrt(((gt - pred) ** 2).mean())\n",
    "    rmse_log = np.sqrt(((np.log(gt) - np.log(pred)) ** 2).mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "    sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
    "\n",
    "    return abs_rel, sq_rel, rmse_trajectory_7, rmse_log, a1, a2, a3\n",
    "\n",
    "# Now, compute errors between the predicted depth maps and ground truth\n",
    "# Collect predicted depth maps from depth_after_imu\n",
    "predicted_depth_maps = [depth.cpu().squeeze(0) for depth in depth_after_imu]\n",
    "\n",
    "errors_trajectory_7 = []\n",
    "\n",
    "for pred_depth_map, gt_depth_map in zip(predicted_depth_maps, depth_gt_list):\n",
    "    pred_depth_map_np = pred_depth_map.detach().numpy() \n",
    "    gt_depth_map_np = gt_depth_map.numpy()\n",
    "    \n",
    "    # Apply mask to valid depth values\n",
    "    mask = (gt_depth_map_np > min_depth) & (gt_depth_map_np < max_depth)\n",
    "    \n",
    "    pred_depth_flat = pred_depth_map_np[mask]\n",
    "    gt_depth_flat = gt_depth_map_np[mask]\n",
    "    \n",
    "    # Ensure predicted depths are within valid range\n",
    "    pred_depth_flat = np.clip(pred_depth_flat, min_depth, max_depth)\n",
    "    \n",
    "    # Compute error metrics\n",
    "    errors_trajectory_7.append(compute_errors(gt_depth_flat, pred_depth_flat))\n",
    "\n",
    "# Compute mean errors\n",
    "mean_errors = np.mean(errors_trajectory_7, axis=0)\n",
    "\n",
    "print(\"\\n  \" + (\"{:>8} | \" * 7).format(\"abs_rel\", \"sq_rel\", \"rmse_trajectory_7\", \"rmse_log\", \"a1\", \"a2\", \"a3\"))\n",
    "print((\"{: 8.3f}  \" * 7).format(*mean_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_trajectory_7 = [item[2] for item in errors_trajectory_7]\n",
    "plt.title(\"RMSE as prediction horizon increases\")\n",
    "plt.plot(rmse_trajectory_7)\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_trajectory_7[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('rmse_trajectories/rmse_trajectory_7.npy', rmse_trajectory_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"velocities/vel_7.npy\", vel_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trajectory 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(\"splits\", \"eigen_midair\", \"{}_files.txt\"))\n",
    "fpath = os.path.join(\"splits\",\"eigen_midair\", \"{}_files.txt\")\n",
    "\n",
    "train_filenames = readlines(fpath.format(\"train\"))\n",
    "\n",
    "train_filenames = sorted(train_filenames, key=custom_sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code\n",
    "# INIT DEPTH PREDICTION\n",
    "min_depth = 0.1\n",
    "max_depth = 80\n",
    "\n",
    "height = 512\n",
    "width = 512\n",
    "batch_size = 1\n",
    "\n",
    "backproject_depth = BackprojectDepth(batch_size, height, width)\n",
    "project_3d = Project3D(batch_size, height, width)\n",
    "fraction_trajectory_8 = train_filenames[24106:24106+100]\n",
    "\n",
    "dataset = datasets.midair.MidAirDataset\n",
    "fpath = os.path.join(\"splits\", \"eigen_midair\", \"{}_files.txt\")\n",
    "data_path = \"MidAir\"\n",
    "\n",
    "print(\"Creating dataset trajectory 1\")\n",
    "dataset_trajectory_8 = dataset(\n",
    "    data_path, fraction_trajectory_8, \n",
    "    height, width,\n",
    "    [0, -1, 1],\n",
    "    select_file_names=True,\n",
    "    num_scales=1, \n",
    "    use_imu=True,\n",
    "    k_imu_clip=5, is_train=False, img_ext='.jpg' \n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "dataloader_trajectory_8 = DataLoader(dataset_trajectory_8, 1, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "list_frames_traj_8 = []\n",
    "list_gt_frames_traj_8 = []\n",
    "depth_gt_list = []  # List to store ground truth depth maps\n",
    "alpha, R_c, R_cbt_bc, delta_t, gravities, velocities = [], [], [], [], [], []\n",
    "\n",
    "avg_velocity = []\n",
    "\n",
    "for idx, sample in enumerate(dataset_trajectory_8):\n",
    "    # Standard processing\n",
    "    for key, ipt in sample.items():\n",
    "        if key in [(\"preint_imu\", -1, 0), (\"preint_imu\", 0, 1)]:\n",
    "            for pkey, pipt in sample[key].items():\n",
    "                sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                if pkey not in [\"v_norm\", \"delta_t\"]:\n",
    "                    pipt = pipt.unsqueeze(0)\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                else:\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "        else:\n",
    "            ipt = ipt.unsqueeze(0)\n",
    "            sample[key] = ipt.to(device, dtype=torch.float32)\n",
    "\n",
    "    if idx == 0:\n",
    "        init_sample = sample\n",
    "        init_image = sample[('color', 0, 0)]\n",
    "        depth_gt = sample[\"disp_gt\"]\n",
    "        depth_gt = (height // 2) / depth_gt.to(torch.float32)\n",
    "        depth_gt = torch.clamp(depth_gt, min_depth, max_depth)\n",
    "        depth_gt = depth_gt[:, 0].detach()\n",
    "\n",
    "    frames = sample[('color', 0, 0)]\n",
    "    disp_gt = sample[\"disp_gt\"]\n",
    "    disp_gt = (height // 2) / disp_gt.to(torch.float32)\n",
    "    disp_gt = torch.clamp(disp_gt, min_depth, max_depth)\n",
    "    depth_gt_sample = disp_gt[:, 0].detach()\n",
    "\n",
    "    # Store ground truth depth maps\n",
    "    depth_gt_list.append(depth_gt_sample.cpu())\n",
    "\n",
    "    # Collect frames for visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(10, 10), nrows=1, ncols=2)\n",
    "    frame_data = frames\n",
    "    im_8 = ax1.imshow(frame_data[0].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    im_9 = ax2.imshow(depth_gt_sample.permute(1, 2, 0).cpu().numpy(), cmap='viridis_r')\n",
    "    list_frames_traj_8.append(im_8)\n",
    "    list_gt_frames_traj_8.append(im_9)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Get IMU parameters\n",
    "    next_imu = sample[('preint_imu', -1, 0)]\n",
    "    alpha.append(next_imu[\"alpha\"])\n",
    "    R_c.append(next_imu[\"R_c\"])\n",
    "    R_cbt_bc.append(next_imu[\"R_cbt_bc\"])\n",
    "    delta_t.append(next_imu[\"delta_t\"])\n",
    "    avg_velocity.append(next_imu[\"v_norm\"])\n",
    "\n",
    "# Compute average velocity\n",
    "vel_8 = torch.mean(torch.stack(avg_velocity), dim=0)\n",
    "print(f\"Average velocity: {vel_8}\")\n",
    "\n",
    "# Add code to create video of the original trajectory\n",
    "image_frames_traj_8 = [im.get_array() for im in list_frames_traj_8]\n",
    "gt_frames_traj_8 = [im.get_array() for im in list_gt_frames_traj_8]\n",
    "\n",
    "# Create a figure and axis for the animation\n",
    "fig, ax = plt.subplots()\n",
    "# Initialize the image on the axis (using the first frame's shape)\n",
    "im = ax.imshow(image_frames_traj_8[0], cmap='viridis')\n",
    "\n",
    "# Update function for animation\n",
    "def update(frame):\n",
    "    im.set_data(frame)\n",
    "    return [im]\n",
    "\n",
    "# Create an animation\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, update, frames=image_frames_traj_8, interval=100, blit=True\n",
    ")\n",
    "\n",
    "# Save the animation as a video file (e.g., MP4)\n",
    "ani.save('Trajectories_anim/trajectory_8.mp4', writer='ffmpeg', fps=25)\n",
    "plt.close(fig)\n",
    "\n",
    "# Depth prediction using the same method as the second file\n",
    "TRANS_SCALE_FACTOR = 5.4\n",
    "pair_inputs = [init_sample[('color', 0, 0)], init_sample[('color', 1, 0)]]\n",
    "\n",
    "# Generate velocity and gravity inputs\n",
    "velo_inputs = [models[\"velo_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "gravity_inputs = [models[\"gravity_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "\n",
    "velocity = models[\"velo\"](velo_inputs)\n",
    "gravity = models[\"gravity\"](gravity_inputs)\n",
    "\n",
    "R_cbt_bc[0] = R_cbt_bc[0]\n",
    "\n",
    "# Get depth prediction\n",
    "with torch.no_grad():\n",
    "    output = models[\"depth\"](models[\"encoder\"](init_image))\n",
    "    disp_trajectory_8 = output\n",
    "\n",
    "# Adjusted depth prediction\n",
    "pred_disp, _ = disp_to_depth(disp_trajectory_8[(\"disp\", 0)], min_depth, max_depth)\n",
    "pred_disp = pred_disp.cpu()[:, 0]\n",
    "pred_depth = 1 / pred_disp\n",
    "\n",
    "# Apply median scaling\n",
    "ratio = np.median(depth_gt.cpu().numpy()) / np.median(pred_depth.cpu().numpy())\n",
    "pred_depth *= ratio\n",
    "pred_depth = pred_depth.to(init_image.device).unsqueeze(0)\n",
    "\n",
    "# Ensure depth values are within valid range\n",
    "pred_depth = torch.clamp(pred_depth, min_depth, max_depth)\n",
    "\n",
    "# Generate poses and depth trajectory\n",
    "poses_depth = get_poses_depth(dataset_trajectory_8, models, alpha, R_c, R_cbt_bc, delta_t, TRANS_SCALE_FACTOR)\n",
    "depth_after_imu, depth_init_trajectory_8, images_after_imu = get_depth_trajectory(\n",
    "    batch_size, init_image, disp_trajectory_8[(\"disp\", 0)], poses_depth, init_sample\n",
    ")\n",
    "\n",
    "# Save depth video\n",
    "get_video_depth(depth_after_imu, \"Depth_anim/depth_trajectory_8.mp4\")\n",
    "\n",
    "# Function to compute errors\n",
    "def compute_errors(gt, pred):\n",
    "    \"\"\"Compute error metrics between predicted and ground truth depths.\"\"\"\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25     ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse_trajectory_8 = np.sqrt(((gt - pred) ** 2).mean())\n",
    "    rmse_log = np.sqrt(((np.log(gt) - np.log(pred)) ** 2).mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "    sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
    "\n",
    "    return abs_rel, sq_rel, rmse_trajectory_8, rmse_log, a1, a2, a3\n",
    "\n",
    "# Now, compute errors between the predicted depth maps and ground truth\n",
    "# Collect predicted depth maps from depth_after_imu\n",
    "predicted_depth_maps = [depth.cpu().squeeze(0) for depth in depth_after_imu]\n",
    "\n",
    "errors_trajectory_8 = []\n",
    "\n",
    "for pred_depth_map, gt_depth_map in zip(predicted_depth_maps, depth_gt_list):\n",
    "    pred_depth_map_np = pred_depth_map.detach().numpy() \n",
    "    gt_depth_map_np = gt_depth_map.numpy()\n",
    "    \n",
    "    # Apply mask to valid depth values\n",
    "    mask = (gt_depth_map_np > min_depth) & (gt_depth_map_np < max_depth)\n",
    "    \n",
    "    pred_depth_flat = pred_depth_map_np[mask]\n",
    "    gt_depth_flat = gt_depth_map_np[mask]\n",
    "    \n",
    "    # Ensure predicted depths are within valid range\n",
    "    pred_depth_flat = np.clip(pred_depth_flat, min_depth, max_depth)\n",
    "    \n",
    "    # Compute error metrics\n",
    "    errors_trajectory_8.append(compute_errors(gt_depth_flat, pred_depth_flat))\n",
    "\n",
    "# Compute mean errors\n",
    "mean_errors = np.mean(errors_trajectory_8, axis=0)\n",
    "\n",
    "print(\"\\n  \" + (\"{:>8} | \" * 7).format(\"abs_rel\", \"sq_rel\", \"rmse_trajectory_8\", \"rmse_log\", \"a1\", \"a2\", \"a3\"))\n",
    "print((\"{: 8.3f}  \" * 7).format(*mean_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_trajectory_8 = [item[2] for item in errors_trajectory_8]\n",
    "plt.title(\"RMSE as prediction horizon increases\")\n",
    "plt.plot(rmse_trajectory_8)\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('rmse_trajectories/rmse_trajectory_8.npy', rmse_trajectory_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"velocities/vel_8.npy\", vel_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trajectory 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(\"splits\", \"eigen_midair\", \"{}_files.txt\"))\n",
    "fpath = os.path.join(\"splits\",\"eigen_midair\", \"{}_files.txt\")\n",
    "\n",
    "train_filenames = readlines(fpath.format(\"train\"))\n",
    "\n",
    "train_filenames = sorted(train_filenames, key=custom_sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code\n",
    "# INIT DEPTH PREDICTION\n",
    "min_depth = 0.1\n",
    "max_depth = 80\n",
    "\n",
    "height = 512\n",
    "width = 512\n",
    "batch_size = 1\n",
    "\n",
    "backproject_depth = BackprojectDepth(batch_size, height, width)\n",
    "project_3d = Project3D(batch_size, height, width)\n",
    "fraction_trajectory_9 = train_filenames[24248:24248+100]\n",
    "\n",
    "dataset = datasets.midair.MidAirDataset\n",
    "fpath = os.path.join(\"splits\", \"eigen_midair\", \"{}_files.txt\")\n",
    "data_path = \"MidAir\"\n",
    "\n",
    "print(\"Creating dataset trajectory 1\")\n",
    "dataset_trajectory_9 = dataset(\n",
    "    data_path, fraction_trajectory_9, \n",
    "    height, width,\n",
    "    [0, -1, 1],\n",
    "    select_file_names=True,\n",
    "    num_scales=1, \n",
    "    use_imu=True,\n",
    "    k_imu_clip=5, is_train=False, img_ext='.jpg' \n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "dataloader_trajectory_9 = DataLoader(dataset_trajectory_9, 1, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "list_frames_traj_9 = []\n",
    "list_gt_frames_traj_9 = []\n",
    "depth_gt_list = []  # List to store ground truth depth maps\n",
    "alpha, R_c, R_cbt_bc, delta_t, gravities, velocities = [], [], [], [], [], []\n",
    "\n",
    "avg_velocity = []\n",
    "\n",
    "for idx, sample in enumerate(dataset_trajectory_9):\n",
    "    # Standard processing\n",
    "    for key, ipt in sample.items():\n",
    "        if key in [(\"preint_imu\", -1, 0), (\"preint_imu\", 0, 1)]:\n",
    "            for pkey, pipt in sample[key].items():\n",
    "                sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                if pkey not in [\"v_norm\", \"delta_t\"]:\n",
    "                    pipt = pipt.unsqueeze(0)\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "                else:\n",
    "                    sample[key][pkey] = pipt.to(device, dtype=torch.float32)\n",
    "        else:\n",
    "            ipt = ipt.unsqueeze(0)\n",
    "            sample[key] = ipt.to(device, dtype=torch.float32)\n",
    "\n",
    "    if idx == 0:\n",
    "        init_sample = sample\n",
    "        init_image = sample[('color', 0, 0)]\n",
    "        depth_gt = sample[\"disp_gt\"]\n",
    "        depth_gt = (height // 2) / depth_gt.to(torch.float32)\n",
    "        depth_gt = torch.clamp(depth_gt, min_depth, max_depth)\n",
    "        depth_gt = depth_gt[:, 0].detach()\n",
    "\n",
    "    frames = sample[('color', 0, 0)]\n",
    "    disp_gt = sample[\"disp_gt\"]\n",
    "    disp_gt = (height // 2) / disp_gt.to(torch.float32)\n",
    "    disp_gt = torch.clamp(disp_gt, min_depth, max_depth)\n",
    "    depth_gt_sample = disp_gt[:, 0].detach()\n",
    "\n",
    "    # Store ground truth depth maps\n",
    "    depth_gt_list.append(depth_gt_sample.cpu())\n",
    "\n",
    "    # Collect frames for visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(10, 10), nrows=1, ncols=2)\n",
    "    frame_data = frames\n",
    "    im_9 = ax1.imshow(frame_data[0].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    im_10 = ax2.imshow(depth_gt_sample.permute(1, 2, 0).cpu().numpy(), cmap='viridis_r')\n",
    "    list_frames_traj_9.append(im_9)\n",
    "    list_gt_frames_traj_9.append(im_10)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Get IMU parameters\n",
    "    next_imu = sample[('preint_imu', -1, 0)]\n",
    "    alpha.append(next_imu[\"alpha\"])\n",
    "    R_c.append(next_imu[\"R_c\"])\n",
    "    R_cbt_bc.append(next_imu[\"R_cbt_bc\"])\n",
    "    delta_t.append(next_imu[\"delta_t\"])\n",
    "    avg_velocity.append(next_imu[\"v_norm\"])\n",
    "\n",
    "# Compute average velocity\n",
    "vel_9 = torch.mean(torch.stack(avg_velocity), dim=0)\n",
    "print(f\"Average velocity: {vel_9}\")\n",
    "\n",
    "# Add code to create video of the original trajectory\n",
    "image_frames_traj_9 = [im.get_array() for im in list_frames_traj_9]\n",
    "gt_frames_traj_9 = [im.get_array() for im in list_gt_frames_traj_9]\n",
    "\n",
    "# Create a figure and axis for the animation\n",
    "fig, ax = plt.subplots()\n",
    "# Initialize the image on the axis (using the first frame's shape)\n",
    "im = ax.imshow(image_frames_traj_9[0], cmap='viridis')\n",
    "\n",
    "# Update function for animation\n",
    "def update(frame):\n",
    "    im.set_data(frame)\n",
    "    return [im]\n",
    "\n",
    "# Create an animation\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, update, frames=image_frames_traj_9, interval=100, blit=True\n",
    ")\n",
    "\n",
    "# Save the animation as a video file (e.g., MP4)\n",
    "ani.save('Trajectories_anim/trajectory_9.mp4', writer='ffmpeg', fps=25)\n",
    "plt.close(fig)\n",
    "\n",
    "# Depth prediction using the same method as the second file\n",
    "TRANS_SCALE_FACTOR = 5.4\n",
    "pair_inputs = [init_sample[('color', 0, 0)], init_sample[('color', 1, 0)]]\n",
    "\n",
    "# Generate velocity and gravity inputs\n",
    "velo_inputs = [models[\"velo_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "gravity_inputs = [models[\"gravity_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "\n",
    "velocity = models[\"velo\"](velo_inputs)\n",
    "gravity = models[\"gravity\"](gravity_inputs)\n",
    "\n",
    "R_cbt_bc[0] = R_cbt_bc[0]\n",
    "\n",
    "# Get depth prediction\n",
    "with torch.no_grad():\n",
    "    output = models[\"depth\"](models[\"encoder\"](init_image))\n",
    "    disp_trajectory_9 = output\n",
    "\n",
    "# Adjusted depth prediction\n",
    "pred_disp, _ = disp_to_depth(disp_trajectory_9[(\"disp\", 0)], min_depth, max_depth)\n",
    "pred_disp = pred_disp.cpu()[:, 0]\n",
    "pred_depth = 1 / pred_disp\n",
    "\n",
    "# Apply median scaling\n",
    "ratio = np.median(depth_gt.cpu().numpy()) / np.median(pred_depth.cpu().numpy())\n",
    "pred_depth *= ratio\n",
    "pred_depth = pred_depth.to(init_image.device).unsqueeze(0)\n",
    "\n",
    "# Ensure depth values are within valid range\n",
    "pred_depth = torch.clamp(pred_depth, min_depth, max_depth)\n",
    "\n",
    "# Generate poses and depth trajectory\n",
    "poses_depth = get_poses_depth(dataset_trajectory_9, models, alpha, R_c, R_cbt_bc, delta_t, TRANS_SCALE_FACTOR)\n",
    "depth_after_imu, depth_init_trajectory_9, images_after_imu = get_depth_trajectory(\n",
    "    batch_size, init_image, disp_trajectory_9[(\"disp\", 0)], poses_depth, init_sample\n",
    ")\n",
    "\n",
    "# Save depth video\n",
    "get_video_depth(depth_after_imu, \"Depth_anim/depth_trajectory_9.mp4\")\n",
    "\n",
    "# Function to compute errors\n",
    "def compute_errors(gt, pred):\n",
    "    \"\"\"Compute error metrics between predicted and ground truth depths.\"\"\"\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25     ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse_trajectory_9 = np.sqrt(((gt - pred) ** 2).mean())\n",
    "    rmse_log = np.sqrt(((np.log(gt) - np.log(pred)) ** 2).mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "    sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
    "\n",
    "    return abs_rel, sq_rel, rmse_trajectory_9, rmse_log, a1, a2, a3\n",
    "\n",
    "# Now, compute errors between the predicted depth maps and ground truth\n",
    "# Collect predicted depth maps from depth_after_imu\n",
    "predicted_depth_maps = [depth.cpu().squeeze(0) for depth in depth_after_imu]\n",
    "\n",
    "errors_trajectory_9 = []\n",
    "\n",
    "for pred_depth_map, gt_depth_map in zip(predicted_depth_maps, depth_gt_list):\n",
    "    pred_depth_map_np = pred_depth_map.detach().numpy() \n",
    "    gt_depth_map_np = gt_depth_map.numpy()\n",
    "    \n",
    "    # Apply mask to valid depth values\n",
    "    mask = (gt_depth_map_np > min_depth) & (gt_depth_map_np < max_depth)\n",
    "    \n",
    "    pred_depth_flat = pred_depth_map_np[mask]\n",
    "    gt_depth_flat = gt_depth_map_np[mask]\n",
    "    \n",
    "    # Ensure predicted depths are within valid range\n",
    "    pred_depth_flat = np.clip(pred_depth_flat, min_depth, max_depth)\n",
    "    \n",
    "    # Compute error metrics\n",
    "    errors_trajectory_9.append(compute_errors(gt_depth_flat, pred_depth_flat))\n",
    "\n",
    "# Compute mean errors\n",
    "mean_errors = np.mean(errors_trajectory_9, axis=0)\n",
    "\n",
    "print(\"\\n  \" + (\"{:>8} | \" * 7).format(\"abs_rel\", \"sq_rel\", \"rmse_trajectory_9\", \"rmse_log\", \"a1\", \"a2\", \"a3\"))\n",
    "print((\"{: 8.3f}  \" * 7).format(*mean_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_trajectory_9 = [item[2] for item in errors_trajectory_9]\n",
    "plt.title(\"RMSE as prediction horizon increases\")\n",
    "plt.plot(rmse_trajectory_9)\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('rmse_trajectories/rmse_trajectory_9.npy', rmse_trajectory_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"velocities/vel_9.npy\", vel_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"velocities/vel_8.npy\", vel_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot trajectories in same frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the stored RMSE values for different trajectories (for the example, I'm loading the same file multiple times)\n",
    "rmse_trajectory_files = [\"/Users/ibrahimhassan/Documents/Documents/thesis_DynaDepth/rmse_trajectories/rmse_trajectory_2.npy\",\n",
    "                         \"/Users/ibrahimhassan/Documents/Documents/thesis_DynaDepth/rmse_trajectories/rmse_trajectory_3.npy\",\n",
    "                         \"/Users/ibrahimhassan/Documents/Documents/thesis_DynaDepth/rmse_trajectories/rmse_trajectory_6.npy\",\n",
    "                         \"/Users/ibrahimhassan/Documents/Documents/thesis_DynaDepth/rmse_trajectories/rmse_trajectory_7.npy\",\n",
    "                         \"/Users/ibrahimhassan/Documents/Documents/thesis_DynaDepth/rmse_trajectories/rmse_trajectory_8.npy\"]  # Example file paths; add others when available\n",
    "\n",
    "\n",
    "velocities_list = [\"/Users/ibrahimhassan/Documents/Documents/thesis_DynaDepth/velocities/vel_2.npy\",\n",
    "                   \"/Users/ibrahimhassan/Documents/Documents/thesis_DynaDepth/velocities/vel_3.npy\",\n",
    "                   \"/Users/ibrahimhassan/Documents/Documents/thesis_DynaDepth/velocities/vel_6.npy\",\n",
    "                   \"/Users/ibrahimhassan/Documents/Documents/thesis_DynaDepth/velocities/vel_7.npy\",\n",
    "                   \"/Users/ibrahimhassan/Documents/Documents/thesis_DynaDepth/velocities/vel_8.npy\"]\n",
    "# Dictionary to hold RMSE values for each trajectory\n",
    "rmse_trajectories = {}\n",
    "\n",
    "# Load each RMSE file and store in the dictionary\n",
    "for idx, file_path in enumerate(rmse_trajectory_files, start=1):\n",
    "    rmse_trajectories[f\"Trajectory_{idx}\"] = np.load(file_path)\n",
    "\n",
    "# Plotting multiple trajectories in the same frame\n",
    "plt.figure(figsize=(10, 6))\n",
    "for trajectory_name, rmse_values in rmse_trajectories.items():\n",
    "    plt.plot(rmse_values, label=trajectory_name)\n",
    "\n",
    "plt.title(\"RMSE as Prediction Horizon Increases for Multiple Trajectories\")\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30 trajectories simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import gc  # Import garbage collector\n",
    "\n",
    "\n",
    "# Assuming 'readlines' and 'custom_sort_key' functions are defined\n",
    "print(os.path.join(\"splits\", \"eigen_midair\", \"{}_files.txt\"))\n",
    "fpath = os.path.join(\"splits\",\"eigen_midair\", \"{}_files.txt\")\n",
    "\n",
    "train_filenames = readlines(fpath.format(\"train\"))\n",
    "\n",
    "train_filenames = sorted(train_filenames, key=custom_sort_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT DEPTH PREDICTION\n",
    "min_depth = 0.1\n",
    "max_depth = 80\n",
    "\n",
    "height = 512\n",
    "width = 512\n",
    "batch_size = 1\n",
    "\n",
    "backproject_depth = BackprojectDepth(batch_size, height, width)\n",
    "project_3d = Project3D(batch_size, height, width)\n",
    "\n",
    "dataset = datasets.midair.MidAirDataset\n",
    "data_path = \"MidAir\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_errors(gt, pred):\n",
    "    \"\"\"Compute error metrics between predicted and ground truth depths.\"\"\"\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25     ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse = np.sqrt(((gt - pred) ** 2).mean())\n",
    "    rmse_log = np.sqrt(((np.log(gt + 1e-6) - np.log(pred + 1e-6)) ** 2).mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / (gt + 1e-6))\n",
    "    sq_rel = np.mean(((gt - pred) ** 2) / (gt + 1e-6))\n",
    "\n",
    "    return abs_rel, sq_rel, rmse, rmse_log, a1, a2, a3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trajectories = 30\n",
    "trajectory_length = 100\n",
    "\n",
    "# Ensure there are enough filenames\n",
    "assert len(train_filenames) >= num_trajectories * trajectory_length, \"Not enough filenames to create trajectories.\"\n",
    "\n",
    "all_rmse_trajectories = {}\n",
    "all_velocities = {}\n",
    "\n",
    "for traj_idx in range(0,num_trajectories):\n",
    "    print(f\"idx: {traj_idx}/{num_trajectories}\")\n",
    "    # Calculate start and end indices for the trajectory in train_filenames\n",
    "    start_idx = traj_idx * trajectory_length\n",
    "    end_idx = start_idx + trajectory_length\n",
    "    \n",
    "    fraction_trajectory = train_filenames[start_idx:end_idx]\n",
    "    \n",
    "    # Create dataset for the trajectory\n",
    "    dataset_trajectory = dataset(\n",
    "        data_path, fraction_trajectory, \n",
    "        height, width,\n",
    "        [0, -1, 1],\n",
    "        select_file_names=True,\n",
    "        num_scales=1, \n",
    "        use_imu=True,\n",
    "        k_imu_clip=5, is_train=False, img_ext='.jpg'\n",
    "    )\n",
    "    \n",
    "    # Initialize lists to store data for this trajectory\n",
    "    depth_gt_list = []  # List to store ground truth depth maps\n",
    "    alpha, R_c, R_cbt_bc, delta_t, gravities, velocities = [], [], [], [], [], []\n",
    "    avg_velocity = []\n",
    "    errors_trajectory = []\n",
    "    \n",
    "    # Data loader for the trajectory\n",
    "    dataloader_trajectory = DataLoader(dataset_trajectory, 1, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    for idx, sample in enumerate(dataset_trajectory):\n",
    "        # Standard processing\n",
    "        for key, ipt in sample.items():\n",
    "            if key in [(\"preint_imu\", -1, 0), (\"preint_imu\", 0, 1)]:\n",
    "                for pkey, pipt in sample[key].items():\n",
    "                    pipt = pipt.to(device, dtype=torch.float32)\n",
    "                    if pkey not in [\"v_norm\", \"delta_t\"]:\n",
    "                        pipt = pipt.unsqueeze(0)\n",
    "                    sample[key][pkey] = pipt\n",
    "            else:\n",
    "                ipt = ipt.unsqueeze(0).to(device, dtype=torch.float32)\n",
    "                sample[key] = ipt\n",
    "        \n",
    "        if idx == 0:\n",
    "            init_sample = sample\n",
    "            init_image = sample[('color', 0, 0)]\n",
    "            disp_gt = sample[\"disp_gt\"]\n",
    "            depth_gt_init = (height // 2) / disp_gt.to(torch.float32)\n",
    "            depth_gt_init = torch.clamp(depth_gt_init, min_depth, max_depth)\n",
    "            depth_gt_init = depth_gt_init[:, 0].detach()\n",
    "        \n",
    "        frames = sample[('color', 0, 0)]\n",
    "        disp_gt = sample[\"disp_gt\"]\n",
    "        disp_gt = (height // 2) / disp_gt.to(torch.float32)\n",
    "        disp_gt = torch.clamp(disp_gt, min_depth, max_depth)\n",
    "        depth_gt_sample = disp_gt[:, 0].detach()\n",
    "        \n",
    "        # Store ground truth depth maps\n",
    "        depth_gt_list.append(depth_gt_sample.cpu())\n",
    "        \n",
    "        # Get IMU parameters\n",
    "        next_imu = sample[('preint_imu', -1, 0)]\n",
    "        alpha.append(next_imu[\"alpha\"])\n",
    "        R_c.append(next_imu[\"R_c\"])\n",
    "        R_cbt_bc.append(next_imu[\"R_cbt_bc\"])\n",
    "        delta_t.append(next_imu[\"delta_t\"])\n",
    "        avg_velocity.append(next_imu[\"v_norm\"])\n",
    "    \n",
    "    # Compute average velocity for this trajectory\n",
    "    vel = torch.mean(torch.stack(avg_velocity), dim=0)\n",
    "    print(f\"Average velocity for trajectory {traj_idx+1}: {vel.item()}\")\n",
    "    all_velocities[f\"Trajectory_{traj_idx+1}\"] = vel.item()\n",
    "    \n",
    "    # Depth prediction using the same method as before\n",
    "    TRANS_SCALE_FACTOR = 5.4\n",
    "    pair_inputs = [init_sample[('color', 0, 0)], init_sample[('color', 1, 0)]]\n",
    "    \n",
    "    # Generate velocity and gravity inputs\n",
    "    velo_inputs = [models[\"velo_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "    gravity_inputs = [models[\"gravity_encoder\"](torch.cat(pair_inputs, 1))]\n",
    "    \n",
    "    velocity_pred = models[\"velo\"](velo_inputs)\n",
    "    gravity = models[\"gravity\"](gravity_inputs)\n",
    "    \n",
    "    R_cbt_bc[0] = R_cbt_bc[0]\n",
    "    \n",
    "    # Get depth prediction\n",
    "    with torch.no_grad():\n",
    "        output = models[\"depth\"](models[\"encoder\"](init_image))\n",
    "        disp_trajectory = output\n",
    "    \n",
    "    # Adjusted depth prediction\n",
    "    pred_disp, _ = disp_to_depth(disp_trajectory[(\"disp\", 0)], min_depth, max_depth)\n",
    "    pred_disp = pred_disp.cpu()[:, 0]\n",
    "    pred_depth = 1 / pred_disp\n",
    "    \n",
    "    # Apply median scaling\n",
    "    ratio = np.median(depth_gt_init.cpu().numpy()) / np.median(pred_depth.cpu().numpy())\n",
    "    pred_depth *= ratio\n",
    "    pred_depth = pred_depth.to(init_image.device).unsqueeze(0)\n",
    "    \n",
    "    # Compute errors between predicted and ground truth depths\n",
    "    ##########################################################\n",
    "    pred_depth_tmp = pred_depth.squeeze()\n",
    "    pred_depth_tmp = pred_depth_tmp.detach().cpu().numpy()\n",
    "    depth_gt_init_tmp = depth_gt_init.squeeze()\n",
    "    depth_gt_init_tmp = depth_gt_init_tmp.detach().cpu().numpy()\n",
    "\n",
    "    mask = (depth_gt_init_tmp > min_depth) & (depth_gt_init_tmp < max_depth)\n",
    "    pred_depth_flat = pred_depth_tmp[mask]\n",
    "\n",
    "    gt_depth_flat = depth_gt_init_tmp[mask]\n",
    "    print(f\"init error : {compute_errors(gt_depth_flat, pred_depth_flat)[2]}\")\n",
    "    ##########################################################\n",
    "    \n",
    "    # Generate poses and depth trajectory\n",
    "    poses_depth = get_poses_depth(dataset_trajectory, models, alpha, R_c, R_cbt_bc, delta_t, TRANS_SCALE_FACTOR)\n",
    "    depth_after_imu, depth_init_trajectory, images_after_imu = get_depth_trajectory(\n",
    "        batch_size, init_image, pred_depth, poses_depth, init_sample\n",
    "    )\n",
    "    \n",
    "    # Now, compute errors between the predicted depth maps and ground truth\n",
    "    # Collect predicted depth maps from depth_after_imu\n",
    "    predicted_depth_maps = [depth.cpu().squeeze(0) for depth in depth_after_imu]\n",
    "    \n",
    "    for pred_depth_map, gt_depth_map in zip(predicted_depth_maps, depth_gt_list):\n",
    "        pred_depth_map_np = pred_depth_map.detach().numpy() \n",
    "        gt_depth_map_np = gt_depth_map.numpy()\n",
    "        \n",
    "        # Apply mask to valid depth values\n",
    "        mask = (gt_depth_map_np > min_depth) & (gt_depth_map_np < max_depth)\n",
    "        \n",
    "        pred_depth_flat = pred_depth_map_np[mask]\n",
    "        gt_depth_flat = gt_depth_map_np[mask]\n",
    "        \n",
    "        # Ensure predicted depths are within valid range\n",
    "        pred_depth_flat = np.clip(pred_depth_flat, min_depth, max_depth)\n",
    "        \n",
    "        # Compute error metrics\n",
    "        errors = compute_errors(gt_depth_flat, pred_depth_flat)\n",
    "        errors_trajectory.append(errors)\n",
    "    \n",
    "    # Extract RMSE values for this trajectory\n",
    "    rmse_values = [item[2] for item in errors_trajectory]\n",
    "    all_rmse_trajectories[f\"Trajectory_{traj_idx+1}\"] = rmse_values\n",
    "\n",
    "    # Optionally, save RMSE values for this trajectory\n",
    "    np.save(f\"rmse_values_trajectory_{traj_idx+1}.npy\", rmse_values)\n",
    "\n",
    "    # Memory Management: Release unnecessary variables and clear cache\n",
    "    del dataset_trajectory\n",
    "    del dataloader_trajectory\n",
    "    del init_sample, init_image, depth_gt_init, disp_gt\n",
    "    del frames\n",
    "    del alpha, R_c, R_cbt_bc, delta_t, avg_velocity\n",
    "    del velo_inputs, gravity_inputs, velocity_pred, gravity\n",
    "    del output, disp_trajectory, pred_disp, pred_depth\n",
    "    del poses_depth, depth_after_imu, depth_init_trajectory, images_after_imu\n",
    "    del predicted_depth_maps, depth_gt_list\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = 'rmse_traj'\n",
    "\n",
    "# Initialize the dictionary to store RMSE values\n",
    "all_rmse_trajectories = {}\n",
    "\n",
    "# Iterate over the files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.npy'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Load the RMSE values from the file\n",
    "        rmse_values = np.load(file_path)\n",
    "        \n",
    "        # Extract the trajectory number from the file name\n",
    "        trajectory_number = file_name.split('_')[-1].split('.')[0]\n",
    "        \n",
    "        # Store the RMSE values in the dictionary\n",
    "        all_rmse_trajectories[f'Trajectory_{trajectory_number}'] = rmse_values\n",
    "\n",
    "# Print the dictionary to verify\n",
    "print(sorted(all_rmse_trajectories.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rmse_trajectories = {key:all_rmse_trajectories[key] for key in all_rmse_trajectories.keys() if all_rmse_trajectories[key][0] <20 and all(value < 25 for value in all_rmse_trajectories[key][:10])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for trajectory_name, rmse_values in all_rmse_trajectories.items():\n",
    "    plt.plot(rmse_values, label=trajectory_name)\n",
    "\n",
    "plt.title(\"RMSE as Prediction Horizon Increases for Multiple Trajectories\")\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for trajectory_name, rmse_values in filtered_rmse_trajectories.items():\n",
    "    plt.plot(rmse_values, color='lightgrey', linewidth=1, label=trajectory_name)\n",
    "\n",
    "# plt.title(\"RMSE as Prediction Horizon Increases for Multiple Trajectories\")\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rmse_trajectories_vel_1 = {key:all_rmse_trajectories[key] for key in all_rmse_trajectories.keys() if all_rmse_trajectories[key][0] <20 and all_velocities[key] >5  and all(value < 25 for value in all_rmse_trajectories[key][:10])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for trajectory_name, rmse_values in filtered_rmse_trajectories_vel_1.items():\n",
    "    plt.plot(rmse_values, color='lightgrey', linewidth=1, label=trajectory_name)\n",
    "\n",
    "plt.title(\"RMSE as Prediction Horizon Increases for Multiple Trajectories\")\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average RMSE excluding the three largest trajectories based on their final RMSE values.\n",
    "sorted_trajectories = sorted(filtered_rmse_trajectories.items(), key=lambda x: x[1][-1])\n",
    "\n",
    "# Exclude the three largest trajectories.\n",
    "filtered_values = [values for _, values in sorted_trajectories[:-3]]\n",
    "\n",
    "# Calculate the mean RMSE at each time step across the remaining trajectories.\n",
    "average_rmse = np.mean(filtered_values, axis=0)\n",
    "\n",
    "# Plotting the RMSE values for each trajectory in light grey\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for trajectory_name, rmse_values in filtered_rmse_trajectories.items():\n",
    "    plt.plot(rmse_values, color='lightgrey', linewidth=1)\n",
    "\n",
    "# Adding the average line in a bold color\n",
    "plt.plot(average_rmse, color='blue', linewidth=3, label='Average RMSE (Excluding 3 Largest)')\n",
    "\n",
    "plt.title(\"RMSE as Prediction Horizon Increases for Multiple Trajectories\")\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rmse_trajectories_vel_1 = {key:all_rmse_trajectories[key] for key in all_rmse_trajectories.keys() if all_rmse_trajectories[key][0] <10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rmse_trajectories_vel_1.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLot of trajectories with initial error smaller than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the RMSE values for each trajectory in light grey\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for trajectory_name, rmse_values in filtered_rmse_trajectories_vel_1.items():\n",
    "    plt.plot(rmse_values, color='lightgrey', linewidth=1)\n",
    "\n",
    "plt.title(\"RMSE as Prediction Horizon Increases for Multiple Trajectories (Excluding 3 Largest)\")\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_error = [all_rmse_trajectories[key][0] for key in all_rmse_trajectories.keys() if all_rmse_trajectories[key][0] <10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average RMSE excluding the three largest trajectories based on their final RMSE values.\n",
    "sorted_trajectories = sorted(filtered_rmse_trajectories_vel_1.items(), key=lambda x: x[1][-1])\n",
    "\n",
    "# Exclude the three largest trajectories.\n",
    "filtered_values = [values for _, values in sorted_trajectories[:-3]]\n",
    "\n",
    "# Calculate the mean RMSE at each time step across the remaining trajectories.\n",
    "average_rmse = np.mean(filtered_values, axis=0)\n",
    "\n",
    "# Plotting the RMSE values for each trajectory in light grey\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for trajectory_name, rmse_values in filtered_rmse_trajectories_vel_1.items():\n",
    "    plt.plot(rmse_values, color='lightgrey', linewidth=1)\n",
    "\n",
    "# Adding the average line in a bold color\n",
    "plt.plot(average_rmse, color='blue', linewidth=3, label='Average RMSE (Excluding 3 Largest)')\n",
    "plt.grid(visible=True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.title(\"RMSE as Prediction Horizon Increases for Multiple Trajectories\")\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rmse_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rmse_trajectories_fil = {key:all_rmse_trajectories[key] for key in all_rmse_trajectories.keys() if all_rmse_trajectories[key][0] <10 and all(value < 28 for value in all_rmse_trajectories[key])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rmse_trajectories_slope = {}\n",
    "for key, rmse_values in filtered_rmse_trajectories_fil.items():\n",
    "    # Calculate average slope over the first 10 values\n",
    "    slopes = np.diff(rmse_values[:10])\n",
    "    average_slope = np.mean(np.abs(slopes))  # take absolute values for positive slope\n",
    "    \n",
    "    # Keep only trajectories with average slope below the threshold\n",
    "    if abs(average_slope) <0.2:\n",
    "        filtered_rmse_trajectories_slope[key] = rmse_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rmse_trajectories_slope\n",
    "count = sum(1 for key, value in filtered_rmse_trajectories_slope.items() if value[0] < 10)\n",
    "print(count)\n",
    "mean_value = np.mean([value[0] for key, value in filtered_rmse_trajectories_slope.items() if value[0] < 10])\n",
    "var_value = np.std([value[0] for key, value in filtered_rmse_trajectories_slope.items() if value[0] < 10])\n",
    "print(mean_value)\n",
    "print(var_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_rmse_trajectories_vel_1 = {key:all_rmse_trajectories[key] for key in all_rmse_trajectories.keys() if all_rmse_trajectories[key][0] <10}\n",
    "# Calculate the average RMSE excluding the three largest trajectories based on their final RMSE values.\n",
    "sorted_trajectories = sorted(filtered_rmse_trajectories_slope.items(), key=lambda x: x[1][-1])\n",
    "\n",
    "# Exclude the three largest trajectories.\n",
    "filtered_values = [values for _, values in sorted_trajectories if values[0] < 10]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the mean RMSE at each time step across the remaining trajectories.\n",
    "average_rmse = np.mean(filtered_values, axis=0)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for trajectory_name, rmse_values in filtered_rmse_trajectories_slope.items():\n",
    "    plt.plot(rmse_values, color='lightgrey', linewidth=1, label=trajectory_name)\n",
    "\n",
    "plt.plot(average_rmse, color='blue', linewidth=3, label='Average RMSE (Excluding 3 Largest)')\n",
    "\n",
    "\n",
    "# plt.title(\"RMSE as Prediction Horizon Increases for Multiple Trajectories\")\n",
    "plt.grid(visible=True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xlim(0,50)\n",
    "plt.xticks(np.arange(0, 51, step=5))\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_new_full",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
